{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distirbuted Training of Mask-RCNN in Amazon SageMaker using S3\n",
    "\n",
    "This notebook is a step-by-step tutorial on distributed tranining of [Mask R-CNN](https://arxiv.org/abs/1703.06870) implemented in [TensorFlow](https://www.tensorflow.org/) framework. Mask R-CNN is also referred to as heavy weight object detection model and it is part of [MLPerf](https://www.mlperf.org/training-results-0-6/).\n",
    "\n",
    "Concretely, we will describe the steps for training [TensorPack Faster-RCNN/Mask-RCNN](https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN) and [AWS Samples Mask R-CNN](https://github.com/aws-samples/mask-rcnn-tensorflow) in [Amazon SageMaker](https://aws.amazon.com/sagemaker/) using [Amazon S3](https://aws.amazon.com/s3/) as data source.\n",
    "\n",
    "The outline of steps is as follows:\n",
    "\n",
    "1. Stage COCO 2017 dataset in [Amazon S3](https://aws.amazon.com/s3/)\n",
    "2. Build SageMaker training image and push it to [Amazon ECR](https://aws.amazon.com/ecr/)\n",
    "3. Configure data input channels\n",
    "4. Configure hyper-prarameters\n",
    "5. Define training metrics\n",
    "6. Define training job and start training\n",
    "\n",
    "Before we get started, let us initialize two python variables ```aws_region``` and ```s3_bucket``` that we will use throughout the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_region =  \"ap-southeast-1\"\n",
    "s3_bucket  =  \"smart-invoice\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage COCO 2017 dataset in Amazon S3\n",
    "\n",
    "We use [COCO 2017 dataset](http://cocodataset.org/#home) for training. We download COCO 2017 training and validation dataset to this notebook instance, extract the files from the dataset archives, and upload the extracted files to your Amazon [S3 bucket](https://docs.aws.amazon.com/en_pv/AmazonS3/latest/gsg/CreatingABucket.html) with the prefix ```mask-rcnn/sagemaker/input/train```. The ```prepare-s3-bucket.sh``` script executes this step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./prepare-s3-bucket.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Using your *Amazon S3 bucket* as argument, run the cell below. If you have already uploaded COCO 2017 dataset to your Amazon S3 bucket *in this AWS region*, you may skip this step. The expected time to execute this step is 20 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!./prepare-s3-bucket.sh {s3_bucket}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and push SageMaker training images\n",
    "\n",
    "For this step, the [IAM Role](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html) attached to this notebook instance needs full access to Amazon ECR service. If you created this notebook instance using the ```./stack-sm.sh``` script in this repository, the IAM Role attached to this notebook instance is already setup with full access to ECR service. \n",
    "\n",
    "Below, we have a choice of two different implementations:\n",
    "\n",
    "1. [TensorPack Faster-RCNN/Mask-RCNN](https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN) implementation supports a maximum per-GPU batch size of 1, and does not support mixed precision. It can be used with mainstream TensorFlow releases.\n",
    "\n",
    "2. [AWS Samples Mask R-CNN](https://github.com/aws-samples/mask-rcnn-tensorflow) is an optimized implementation that supports a maximum batch size of 4 and supports mixed precision. This implementation uses TensorFlow base version 1.13 augmented with custom TensorFlow ops. \n",
    "\n",
    "It is recommended that you build and push both SageMaker training images and use either image for training later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorPack Faster-RCNN/Mask-RCNN\n",
    "\n",
    "Use ```./container/build_tools/build_and_push.sh``` script to build and push the TensorPack Faster-RCNN/Mask-RCNN  training image to Amazon ECR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./container/build_tools/build_and_push.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your *AWS region* as argument, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "! ./container/build_tools/build_and_push.sh {aws_region}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set ```tensorpack_image``` below to Amazon ECR URI of the image you pushed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorpack_image = \"393782509758.dkr.ecr.ap-southeast-1.amazonaws.com/mask-rcnn-tensorpack-sagemaker:tf1.13-tp26664c3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Samples Mask R-CNN\n",
    "Use ```./container-optimized/build_tools/build_and_push.sh``` script to build and push the AWS Samples Mask R-CNN training image to Amazon ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./container-optimized/build_tools/build_and_push.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your *AWS region* as argument, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "! ./container-optimized/build_tools/build_and_push.sh {aws_region}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Set ```aws_samples_image``` below to Amazon ECR URI of the image you pushed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_samples_image = \"393782509758.dkr.ecr.ap-southeast-1.amazonaws.com/mask-rcnn-tensorflow-sagemaker:tf1.13-153442b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Initialization \n",
    "We have staged the data and we have built and pushed the training docker image to Amazon ECR. Now we are ready to start using Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Execution Role:arn:aws:iam::393782509758:role/service-role/AmazonSageMaker-ExecutionRole-20191115T140457\n",
      "AWS account:393782509758\n",
      "AWS region:ap-southeast-1\n",
      "CPU times: user 782 ms, sys: 79.1 ms, total: 861 ms\n",
      "Wall time: 1.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "role = get_execution_role() # provide a pre-existing role ARN as an alternative to creating a new role\n",
    "print(f'SageMaker Execution Role:{role}')\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "print(f'AWS account:{account}')\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "print(f'AWS region:{region}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set ```training_image``` to the Amazon ECR image URI you saved in a previous step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image: 393782509758.dkr.ecr.ap-southeast-1.amazonaws.com/mask-rcnn-tensorflow-sagemaker:tf1.13-153442b\n"
     ]
    }
   ],
   "source": [
    "training_image =  aws_samples_image# set to tensorpack_image or aws_samples_image \n",
    "print(f'Training image: {training_image}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define SageMaker Data Channels\n",
    "In this step, we define SageMaker *train* data channel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"mask-rcnn/sagemaker\" #prefix in your S3 bucket\n",
    "\n",
    "s3train = f's3://{s3_bucket}/{prefix}/input/test'\n",
    "\n",
    "\n",
    "train = sagemaker.session.s3_input(s3train, distribution='FullyReplicated', \n",
    "                        content_type='application/tfrecord', s3_data_type='S3Prefix')\n",
    "\n",
    "\n",
    "data_channels = {'train': train}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the model output location in S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = f's3://{s3_bucket}/{prefix}/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Hyper-parameters\n",
    "Next, we define the hyper-parameters. \n",
    "\n",
    "Note, some hyper-parameters are different between the two implementations. The batch size per GPU in TensorPack Faster-RCNN/Mask-RCNN is fixed at 1, but is configurable in AWS Samples Mask-RCNN. The learning rate schedule is specified in units of steps in TensorPack Faster-RCNN/Mask-RCNN, but in epochs in AWS Samples Mask-RCNN.\n",
    "\n",
    "The detault learning rate schedule values shown below correspond to training for a total of 24 epochs, at 120,000 images per epoch.\n",
    "\n",
    "<table align='left'>\n",
    "    <caption>TensorPack Faster-RCNN/Mask-RCNN  Hyper-parameters</caption>\n",
    "    <tr>\n",
    "    <th style=\"text-align:center\">Hyper-parameter</th>\n",
    "    <th style=\"text-align:center\">Description</th>\n",
    "    <th style=\"text-align:center\">Default</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">mode_fpn</td>\n",
    "        <td style=\"text-align:left\">Flag to indicate use of Feature Pyramid Network (FPN) in the Mask R-CNN model backbone</td>\n",
    "        <td style=\"text-align:center\">\"True\"</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td style=\"text-align:center\">mode_mask</td>\n",
    "        <td style=\"text-align:left\">A value of \"False\" means Faster-RCNN model, \"True\" means Mask R-CNN moodel</td>\n",
    "        <td style=\"text-align:center\">\"True\"</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td style=\"text-align:center\">eval_period</td>\n",
    "        <td style=\"text-align:left\">Number of epochs period for evaluation during training</td>\n",
    "        <td style=\"text-align:center\">1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">lr_schedule</td>\n",
    "        <td style=\"text-align:left\">Learning rate schedule in training steps</td>\n",
    "        <td style=\"text-align:center\">'[240000, 320000, 360000]'</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">batch_norm</td>\n",
    "        <td style=\"text-align:left\">Batch normalization option ('FreezeBN', 'SyncBN', 'GN', 'None') </td>\n",
    "        <td style=\"text-align:center\">'FreezeBN'</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">images_per_epoch</td>\n",
    "        <td style=\"text-align:left\">Images per epoch </td>\n",
    "        <td style=\"text-align:center\">120000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">data_train</td>\n",
    "        <td style=\"text-align:left\">Training data under data directory</td>\n",
    "        <td style=\"text-align:center\">'coco_train2017'</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">data_val</td>\n",
    "        <td style=\"text-align:left\">Validation data under data directory</td>\n",
    "        <td style=\"text-align:center\">'coco_val2017'</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">resnet_arch</td>\n",
    "        <td style=\"text-align:left\">Must be 'resnet50' or 'resnet101'</td>\n",
    "        <td style=\"text-align:center\">'resnet50'</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">backbone_weights</td>\n",
    "        <td style=\"text-align:left\">Pre-trained model weights</td>\n",
    "        <td style=\"text-align:center\">'ImageNet-R50-AlignPadding.npz'</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "    \n",
    "<table align='left'>\n",
    "    <caption>AWS Samples Mask-RCNN  Hyper-parameters</caption>\n",
    "    <tr>\n",
    "    <th style=\"text-align:center\">Hyper-parameter</th>\n",
    "    <th style=\"text-align:center\">Description</th>\n",
    "    <th style=\"text-align:center\">Default</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">mode_fpn</td>\n",
    "        <td style=\"text-align:left\">Flag to indicate use of Feature Pyramid Network (FPN) in the Mask R-CNN model backbone</td>\n",
    "        <td style=\"text-align:center\">\"True\"</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td style=\"text-align:center\">mode_mask</td>\n",
    "        <td style=\"text-align:left\">A value of \"False\" means Faster-RCNN model, \"True\" means Mask R-CNN moodel</td>\n",
    "        <td style=\"text-align:center\">\"True\"</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td style=\"text-align:center\">eval_period</td>\n",
    "        <td style=\"text-align:left\">Number of epochs period for evaluation during training</td>\n",
    "        <td style=\"text-align:center\">1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">lr_epoch_schedule</td>\n",
    "        <td style=\"text-align:left\">Learning rate schedule in epochs</td>\n",
    "        <td style=\"text-align:center\">'[(16, 0.1), (20, 0.01), (24, None)]'</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">batch_size_per_gpu</td>\n",
    "        <td style=\"text-align:left\">Batch size per gpu ( Minimum 1, Maximum 4)</td>\n",
    "        <td style=\"text-align:center\">4</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">batch_norm</td>\n",
    "        <td style=\"text-align:left\">Batch normalization option ('FreezeBN', 'SyncBN', 'GN', 'None') </td>\n",
    "        <td style=\"text-align:center\">'FreezeBN'</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">images_per_epoch</td>\n",
    "        <td style=\"text-align:left\">Images per epoch </td>\n",
    "        <td style=\"text-align:center\">120000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">data_train</td>\n",
    "        <td style=\"text-align:left\">Training data under data directory</td>\n",
    "        <td style=\"text-align:center\">'train2017'</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">data_val</td>\n",
    "        <td style=\"text-align:left\">Validation data under data directory</td>\n",
    "        <td style=\"text-align:center\">'val2017'</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">resnet_arch</td>\n",
    "        <td style=\"text-align:left\">Must be 'resnet50' or 'resnet101'</td>\n",
    "        <td style=\"text-align:center\">'resnet50'</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">backbone_weights</td>\n",
    "        <td style=\"text-align:left\">Pre-trained model weights</td>\n",
    "        <td style=\"text-align:center\">'ImageNet-R50-AlignPadding.npz'</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "                    \"mode_fpn\": \"True\",\n",
    "                    \"mode_mask\": \"True\",\n",
    "                    \"eval_period\": 1,\n",
    "                    \"batch_norm\": \"FreezeBN\",\n",
    "                    \"batch_size_per_gpu\": 1,\n",
    "                    \"images_per_epoch\": 1\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Metrics\n",
    "Next, we define the regular expressions that SageMaker uses to extract algorithm metrics from training logs and send them to [AWS CloudWatch metrics](https://docs.aws.amazon.com/en_pv/AmazonCloudWatch/latest/monitoring/working_with_metrics.html). These algorithm metrics are visualized in SageMaker console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "             {\n",
    "                \"Name\": \"fastrcnn_losses/box_loss\",\n",
    "                \"Regex\": \".*fastrcnn_losses/box_loss:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"fastrcnn_losses/label_loss\",\n",
    "                \"Regex\": \".*fastrcnn_losses/label_loss:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"fastrcnn_losses/label_metrics/accuracy\",\n",
    "                \"Regex\": \".*fastrcnn_losses/label_metrics/accuracy:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"fastrcnn_losses/label_metrics/false_negative\",\n",
    "                \"Regex\": \".*fastrcnn_losses/label_metrics/false_negative:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"fastrcnn_losses/label_metrics/fg_accuracy\",\n",
    "                \"Regex\": \".*fastrcnn_losses/label_metrics/fg_accuracy:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"fastrcnn_losses/num_fg_label\",\n",
    "                \"Regex\": \".*fastrcnn_losses/num_fg_label:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "             {\n",
    "                \"Name\": \"maskrcnn_loss/accuracy\",\n",
    "                \"Regex\": \".*maskrcnn_loss/accuracy:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"maskrcnn_loss/fg_pixel_ratio\",\n",
    "                \"Regex\": \".*maskrcnn_loss/fg_pixel_ratio:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"maskrcnn_loss/maskrcnn_loss\",\n",
    "                \"Regex\": \".*maskrcnn_loss/maskrcnn_loss:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"maskrcnn_loss/pos_accuracy\",\n",
    "                \"Regex\": \".*maskrcnn_loss/pos_accuracy:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"mAP(bbox)/IoU=0.5\",\n",
    "                \"Regex\": \".*mAP\\\\(bbox\\\\)/IoU=0\\\\.5:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"mAP(bbox)/IoU=0.5:0.95\",\n",
    "                \"Regex\": \".*mAP\\\\(bbox\\\\)/IoU=0\\\\.5:0\\\\.95:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"mAP(bbox)/IoU=0.75\",\n",
    "                \"Regex\": \".*mAP\\\\(bbox\\\\)/IoU=0\\\\.75:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"mAP(bbox)/large\",\n",
    "                \"Regex\": \".*mAP\\\\(bbox\\\\)/large:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"mAP(bbox)/medium\",\n",
    "                \"Regex\": \".*mAP\\\\(bbox\\\\)/medium:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"mAP(bbox)/small\",\n",
    "                \"Regex\": \".*mAP\\\\(bbox\\\\)/small:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"mAP(segm)/IoU=0.5\",\n",
    "                \"Regex\": \".*mAP\\\\(segm\\\\)/IoU=0\\\\.5:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"mAP(segm)/IoU=0.5:0.95\",\n",
    "                \"Regex\": \".*mAP\\\\(segm\\\\)/IoU=0\\\\.5:0\\\\.95:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"mAP(segm)/IoU=0.75\",\n",
    "                \"Regex\": \".*mAP\\\\(segm\\\\)/IoU=0\\\\.75:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"mAP(segm)/large\",\n",
    "                \"Regex\": \".*mAP\\\\(segm\\\\)/large:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"mAP(segm)/medium\",\n",
    "                \"Regex\": \".*mAP\\\\(segm\\\\)/medium:\\\\s*(\\\\S+).*\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"mAP(segm)/small\",\n",
    "                \"Regex\": \".*mAP\\\\(segm\\\\)/small:\\\\s*(\\\\S+).*\"\n",
    "            }  \n",
    "            \n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define SageMaker Training Job\n",
    "\n",
    "Next, we use SageMaker [Estimator](https://sagemaker.readthedocs.io/en/stable/estimators.html) API to define a SageMaker Training Job. \n",
    "\n",
    "We recommned using 32 GPUs, so we set ```train_instance_count=4``` and ```train_instance_type='ml.p3.16xlarge'```, because there are 8 Tesla V100 GPUs per ```ml.p3.16xlarge``` instance. We recommend using 100 GB [Amazon EBS](https://aws.amazon.com/ebs/) storage volume with each training instance, so we set ```train_volume_size = 100```. We want to replicate training data to each training instance, so we set ```input_mode= 'File'```.\n",
    "\n",
    "We run the training job in your private VPC, so we need to set the ```subnets``` and ```security_group_ids``` prior to running the cell below. You may specify multiple subnet ids in the ```subnets``` list. The subnets included in the ```sunbets``` list must be part of the output of  ```./stack-sm.sh``` CloudFormation stack script used to create this notebook instance. Specify only one security group id in ```security_group_ids``` list. The security group id must be part of the output of  ```./stack-sm.sh``` script.\n",
    "\n",
    "For ```train_instance_type``` below, you have the option to use ```ml.p3.16xlarge``` with 16 GB per-GPU memory and 25 Gbs network interconnectivity, or ```ml.p3dn.24xlarge``` with 32 GB per-GPU memory and 100 Gbs network interconnectivity. The ```ml.p3dn.24xlarge``` instance type offers significantly better performance than ```ml.p3.16xlarge``` for Mask R-CNN distributed TensorFlow training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# security_group_ids =  # ['sg-xxxxxxxx']\n",
    "# subnets =      # [ 'subnet-xxxxxxx']\n",
    "sagemaker_session = sagemaker.session.Session(boto_session=session)\n",
    "mask_rcnn_estimator = Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.p3.2xlarge',\n",
    "                                         #train_instance_type='local_gpu',\n",
    "                                         train_volume_size = 50,\n",
    "                                         train_max_run = 100,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sagemaker_session, \n",
    "                                         hyperparameters = hyperparameters,\n",
    "                                         metric_definitions = metric_definitions,\n",
    "                                         base_job_name=\"mask-rcnn-s3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we launch the SageMaker training job. \n",
    "\n",
    "The estimated time for downloading data to all the training instances is 20 minutes. The time to complete the training depends on type and number of training instances, and the training image used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-02 10:49:58 Starting - Starting the training job...\n",
      "2020-04-02 10:49:59 Starting - Launching requested ML instances......\n",
      "2020-04-02 10:51:00 Starting - Preparing the instances for training......\n",
      "2020-04-02 10:52:11 Downloading - Downloading input data\n",
      "2020-04-02 10:52:11 Training - Downloading the training image............\n",
      "2020-04-02 10:54:23 Training - Training image download completed. Training in progress..\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mLimited tf.compat.v2.summary API due to missing TensorBoard installation\u001b[0m\n",
      "\u001b[34m2020-04-02 10:54:27,166 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-04-02 10:54:27,167 sagemaker-containers INFO     Failed to parse hyperparameter batch_norm value FreezeBN to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-02 10:54:27,167 sagemaker-containers INFO     Failed to parse hyperparameter mode_mask value True to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-02 10:54:27,167 sagemaker-containers INFO     Failed to parse hyperparameter mode_fpn value True to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-02 10:54:27,216 sagemaker-containers INFO     Failed to parse hyperparameter batch_norm value FreezeBN to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-02 10:54:27,216 sagemaker-containers INFO     Failed to parse hyperparameter mode_mask value True to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-02 10:54:27,216 sagemaker-containers INFO     Failed to parse hyperparameter mode_fpn value True to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-02 10:54:27,235 sagemaker-containers INFO     Failed to parse hyperparameter batch_norm value FreezeBN to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-02 10:54:27,235 sagemaker-containers INFO     Failed to parse hyperparameter mode_mask value True to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-02 10:54:27,236 sagemaker-containers INFO     Failed to parse hyperparameter mode_fpn value True to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-02 10:54:27,268 sagemaker-containers INFO     Failed to parse hyperparameter batch_norm value FreezeBN to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-02 10:54:27,268 sagemaker-containers INFO     Failed to parse hyperparameter mode_mask value True to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-02 10:54:27,268 sagemaker-containers INFO     Failed to parse hyperparameter mode_fpn value True to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-04-02 10:54:27,297 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eval_period\": 1,\n",
      "        \"batch_norm\": \"FreezeBN\",\n",
      "        \"images_per_epoch\": 1,\n",
      "        \"batch_size_per_gpu\": 1,\n",
      "        \"mode_mask\": \"True\",\n",
      "        \"mode_fpn\": \"True\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"application/tfrecord\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"mask-rcnn-s3-2020-04-02-10-49-58-217\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_norm\":\"FreezeBN\",\"batch_size_per_gpu\":1,\"eval_period\":1,\"images_per_epoch\":1,\"mode_fpn\":\"True\",\"mode_mask\":\"True\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"application/tfrecord\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_norm\":\"FreezeBN\",\"batch_size_per_gpu\":1,\"eval_period\":1,\"images_per_epoch\":1,\"mode_fpn\":\"True\",\"mode_mask\":\"True\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"application/tfrecord\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mask-rcnn-s3-2020-04-02-10-49-58-217\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_norm\",\"FreezeBN\",\"--batch_size_per_gpu\",\"1\",\"--eval_period\",\"1\",\"--images_per_epoch\",\"1\",\"--mode_fpn\",\"True\",\"--mode_mask\",\"True\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_PERIOD=1\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_NORM=FreezeBN\u001b[0m\n",
      "\u001b[34mSM_HP_IMAGES_PER_EPOCH=1\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE_PER_GPU=1\u001b[0m\n",
      "\u001b[34mSM_HP_MODE_MASK=True\u001b[0m\n",
      "\u001b[34mSM_HP_MODE_FPN=True\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages:/mask-rcnn-tensorflow\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 train.py --batch_norm FreezeBN --batch_size_per_gpu 1 --eval_period 1 --images_per_epoch 1 --mode_fpn True --mode_mask True\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m{'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/3a9ea992-0c59-4b02-8a34-6dbcf3a3bed6',\n",
      " 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2',\n",
      " 'AWS_REGION': 'ap-southeast-1',\n",
      " 'CUDA_PKG_VERSION': '10-0=10.0.130-1',\n",
      " 'CUDA_VERSION': '10.0.130',\n",
      " 'CURRENT_HOST': 'algo-1',\n",
      " 'DMLC_INTERFACE': 'eth0',\n",
      " 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/980c1d8d-8049-4562-8a05-c2ca836fef2a',\n",
      " 'HOME': '/root',\n",
      " 'HOROVOD_VERSION': '0.18.1',\n",
      " 'HOSTNAME': 'ip-10-0-98-32.ap-southeast-1.compute.internal',\n",
      " 'LANG': 'C.UTF-8',\n",
      " 'LC_ALL': 'C.UTF-8',\n",
      " 'LD_LIBRARY_PATH': '/usr/local/openmpi/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64',\n",
      " 'NVIDIA_DRIVER_CAPABILITIES': 'utility,compute',\n",
      " 'NVIDIA_REQUIRE_CUDA': 'cuda>=10.0 '\n",
      "                        'brand=tesla,driver>=384,driver<385 '\n",
      "                        'brand=tesla,driver>=410,driver<411',\n",
      " 'NVIDIA_VISIBLE_DEVICES': 'all',\n",
      " 'PATH': '/usr/local/nvidia/bin:/usr/local/openmpi/bin/:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n",
      " 'PYTHONDONTWRITEBYTECODE': '1',\n",
      " 'PYTHONIOENCODING': 'UTF-8',\n",
      " 'PYTHONPATH': '/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages:/mask-rcnn-tensorflow',\n",
      " 'PYTHONUNBUFFERED': '1',\n",
      " 'S3_REGION': '',\n",
      " 'S3_USE_HTTPS': '1',\n",
      " 'SAGEMAKER_JOB_NAME': '',\n",
      " 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker',\n",
      " 'SAGEMAKER_PROGRAM': 'train.py',\n",
      " 'SAGEMAKER_REGION': '',\n",
      " 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_tensorflow_container.training:main',\n",
      " 'SM_CHANNELS': '[\"train\"]',\n",
      " 'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train',\n",
      " 'SM_CURRENT_HOST': 'algo-1',\n",
      " 'SM_FRAMEWORK_MODULE': 'sagemaker_tensorflow_container.training:main',\n",
      " 'SM_FRAMEWORK_PARAMS': '{}',\n",
      " 'SM_HOSTS': '[\"algo-1\"]',\n",
      " 'SM_HPS': '{\"batch_norm\":\"FreezeBN\",\"batch_size_per_gpu\":1,\"eval_period\":1,\"images_per_epoch\":1,\"mode_fpn\":\"True\",\"mode_mask\":\"True\"}',\n",
      " 'SM_HP_BATCH_NORM': 'FreezeBN',\n",
      " 'SM_HP_BATCH_SIZE_PER_GPU': '1',\n",
      " 'SM_HP_EVAL_PERIOD': '1',\n",
      " 'SM_HP_IMAGES_PER_EPOCH': '1',\n",
      " 'SM_HP_MODE_FPN': 'True',\n",
      " 'SM_HP_MODE_MASK': 'True',\n",
      " 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config',\n",
      " 'SM_INPUT_DATA_CONFIG': '{\"train\":{\"ContentType\":\"application/tfrecord\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}',\n",
      " 'SM_INPUT_DIR': '/opt/ml/input',\n",
      " 'SM_LOG_LEVEL': '20',\n",
      " 'SM_MODEL_DIR': '/opt/ml/model',\n",
      " 'SM_MODULE_DIR': '/opt/ml/code',\n",
      " 'SM_MODULE_NAME': 'train',\n",
      " 'SM_NETWORK_INTERFACE_NAME': 'eth0',\n",
      " 'SM_NUM_CPUS': '8',\n",
      " 'SM_NUM_GPUS': '1',\n",
      " 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data',\n",
      " 'SM_OUTPUT_DIR': '/opt/ml/output',\n",
      " 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate',\n",
      " 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}',\n",
      " 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_norm\":\"FreezeBN\",\"batch_size_per_gpu\":1,\"eval_period\":1,\"images_per_epoch\":1,\"mode_fpn\":\"True\",\"mode_mask\":\"True\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"application/tfrecord\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mask-rcnn-s3-2020-04-02-10-49-58-217\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}',\n",
      " 'SM_USER_ARGS': '[\"--batch_norm\",\"FreezeBN\",\"--batch_size_per_gpu\",\"1\",\"--eval_period\",\"1\",\"--images_per_epoch\",\"1\",\"--mode_fpn\",\"True\",\"--mode_mask\",\"True\"]',\n",
      " 'SM_USER_ENTRY_POINT': 'train.py',\n",
      " 'TF_CPP_MIN_LOG_LEVEL': '1',\n",
      " 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:ap-southeast-1:393782509758:training-job/mask-rcnn-s3-2020-04-02-10-49-58-217',\n",
      " 'TRAINING_JOB_NAME': 'mask-rcnn-s3-2020-04-02-10-49-58-217'}\u001b[0m\n",
      "\u001b[34mpre-setup check\u001b[0m\n",
      "\u001b[34mhosts that aren't SSHable yet: %s ['algo-1']\u001b[0m\n",
      "\u001b[34mtesting connection to host %s algo-1\u001b[0m\n",
      "\u001b[34mcan't connect to host %s algo-1\u001b[0m\n",
      "\u001b[34mhosts that aren't SSHable yet: %s ['algo-1']\u001b[0m\n",
      "\u001b[34mtesting connection to host %s algo-1\u001b[0m\n",
      "\u001b[34mcan connect to host %s algo-1\u001b[0m\n",
      "\u001b[34mMaster: algo-1\u001b[0m\n",
      "\u001b[34m--------Begin MPI Run Command----------\u001b[0m\n",
      "\u001b[34mHOROVOD_CYCLE_TIME=0.5 \\\u001b[0m\n",
      "\u001b[34mHOROVOD_FUSION_THRESHOLD=67108864 \\\u001b[0m\n",
      "\u001b[34mmpirun -np 1 \\\u001b[0m\n",
      "\u001b[34m--host algo-1:1 \\\u001b[0m\n",
      "\u001b[34m--allow-run-as-root \\\u001b[0m\n",
      "\u001b[34m--display-map \\\u001b[0m\n",
      "\u001b[34m--tag-output \\\u001b[0m\n",
      "\u001b[34m-mca btl_tcp_if_include eth0 \\\u001b[0m\n",
      "\u001b[34m-mca oob_tcp_if_include eth0 \\\u001b[0m\n",
      "\u001b[34m-x NCCL_SOCKET_IFNAME=eth0 \\\u001b[0m\n",
      "\u001b[34m--mca plm_rsh_no_tree_spawn 1 \\\u001b[0m\n",
      "\u001b[34m-bind-to none -map-by slot \\\u001b[0m\n",
      "\u001b[34m-mca pml ob1 -mca btl ^openib \\\u001b[0m\n",
      "\u001b[34m-mca orte_abort_on_non_zero_status 1 \\\u001b[0m\n",
      "\u001b[34m-x TENSORPACK_FP16=1 \\\u001b[0m\n",
      "\u001b[34m-x NCCL_MIN_NRINGS=8 -x NCCL_DEBUG=INFO \\\u001b[0m\n",
      "\u001b[34m-x HOROVOD_CYCLE_TIME -x HOROVOD_FUSION_THRESHOLD \\\u001b[0m\n",
      "\u001b[34m-x LD_LIBRARY_PATH -x PATH \\\u001b[0m\n",
      "\u001b[34m--output-filename /opt/ml/model  \\\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 /mask-rcnn-tensorflow/MaskRCNN/train.py --logdir /opt/ml/model --fp16 --throughput_log_freq=2000 --images_per_epoch 1 --config MODE_FPN=True MODE_MASK=True DATA.BASEDIR=/opt/ml/input/data/train BACKBONE.RESNET_NUM_BLOCKS='[3, 4, 6, 3]' BACKBONE.WEIGHTS=/opt/ml/input/data/train/pretrained-models/ImageNet-R50-AlignPadding.npz BACKBONE.NORM=FreezeBN DATA.TRAIN='[\"train2017\"]' DATA.VAL='(\"val2017\",)' TRAIN.BATCH_SIZE_PER_GPU=1 TRAIN.EVAL_PERIOD=1 TRAIN.LR_EPOCH_SCHEDULE='[(16, 0.1), (20, 0.01), (24, None)]' RPN.TOPK_PER_IMAGE=True PREPROC.PREDEFINED_PADDING=True TRAIN.GRADIENT_CLIP=0 TRAINER=horovod\u001b[0m\n",
      "\u001b[34m--------End MPI Run Comamnd------------\u001b[0m\n",
      "\u001b[34mData for JOB [38739,1] offset 0 Total slots allocated 1\n",
      "\u001b[0m\n",
      "\u001b[34m========================   JOB MAP   ========================\n",
      "\u001b[0m\n",
      "\u001b[34mData for node: ip-10-0-98-32#011Num slots: 1#011Max slots: 0#011Num procs: 1\u001b[0m\n",
      "\u001b[34mProcess OMPI jobid: [38739,1] App: 0 Process rank: 0 Bound: N/A\n",
      "\u001b[0m\n",
      "\u001b[34m=============================================================\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Limited tf.compat.v2.summary API due to missing TensorBoard installation\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:33 @train.py:207]#033[0m Horovod Rank=0, Size=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:33 @logger.py:89]#033[0m Argv: /mask-rcnn-tensorflow/MaskRCNN/train.py --logdir /opt/ml/model --fp16 --throughput_log_freq=2000 --images_per_epoch 1 --config MODE_FPN=True MODE_MASK=True DATA.BASEDIR=/opt/ml/input/data/train BACKBONE.RESNET_NUM_BLOCKS=[3, 4, 6, 3] BACKBONE.WEIGHTS=/opt/ml/input/data/train/pretrained-models/ImageNet-R50-AlignPadding.npz BACKBONE.NORM=FreezeBN DATA.TRAIN=[\"train2017\"] DATA.VAL=(\"val2017\",) TRAIN.BATCH_SIZE_PER_GPU=1 TRAIN.EVAL_PERIOD=1 TRAIN.LR_EPOCH_SCHEDULE=[(16, 0.1), (20, 0.01), (24, None)] RPN.TOPK_PER_IMAGE=True PREPROC.PREDEFINED_PADDING=True TRAIN.GRADIENT_CLIP=0 TRAINER=horovod\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:33 @train.py:121]#033[0m git status\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @train.py:122]#033[0m On branch master\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Your branch is behind 'origin/master' by 155 commits, and can be fast-forwarded.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:  (use \"git pull\" to update your local branch)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Changes not staged for commit:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:  (use \"git add <file>...\" to update what will be committed)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:  (use \"git checkout -- <file>...\" to discard changes in working directory)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#011modified:   tensorpack/libinfo.py\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:no changes added to commit (use \"git add\" and/or \"git commit -a\")\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @train.py:121]#033[0m git rev-parse HEAD\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @train.py:122]#033[0m 153442bc70b06e59f2bbeadc4d359b240f64cbc2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @train.py:121]#033[0m git diff\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @train.py:122]#033[0m diff --git a/tensorpack/libinfo.py b/tensorpack/libinfo.py\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index 6d548ac..024f6da 100644\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:--- a/tensorpack/libinfo.py\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:+++ b/tensorpack/libinfo.py\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:@@ -63,4 +63,4 @@ except ImportError:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: # These lines will be programatically read/write by setup.py\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: # Don't touch them.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: __version__ = '0.9.0.1'\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:-__git_version__ = __version__\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:+__git_version__ = \"v0.0.0-16-g153442b-dirty\"\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\\ No newline at end of file\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @train.py:121]#033[0m env\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @train.py:122]#033[0m OMPI_MCA_pml=ob1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_pmix=^s1,s2,cray,isolated\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_FILE_LOCATION=/tmp/ompi.ip-10-0-98-32.0/pid.34/0/0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_rmaps_base_display_map=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NCCL_MIN_NRINGS=8\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NCCL_DEBUG=INFO\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PYTHONIOENCODING=UTF-8\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_ID=2538799105.0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NCCL_SOCKET_IFNAME=eth0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SAGEMAKER_PROGRAM=train.py\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:HOROVOD_VERSION=0.18.1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_ess=pmi\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_COMM_WORLD_NODE_RANK=0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_FIRST_RANKS=0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_COMM_WORLD_RANK=0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:HOSTNAME=ip-10-0-98-32.ap-southeast-1.compute.internal\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_RANK=0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:TF_USE_CUDNN_BATCHNORM_SPATIAL_PERSISTENT=0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:LD_LIBRARY_PATH=/usr/local/lib:/usr/local/openmpi/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SHLVL=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_orte_tmpdir_base=/tmp\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:TF_GPU_THREAD_COUNT=2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:HOME=/root\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_orte_num_nodes=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_orte_jobfam_session_dir=/tmp/ompi.ip-10-0-98-32.0/pid.34\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_APP_CTX_NUM_PROCS=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_NAMESPACE=2538799105\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_DSTORE_21_BASE_PATH=/tmp/ompi.ip-10-0-98-32.0/pid.34/pmix_dstor_ds21_34\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_MCA_mca_base_component_show_load_errors=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"application/tfrecord\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_GDS_MODULE=ds21,ds12,hash\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_SYSTEM_TMPDIR=/tmp\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:TF_AVGPOOL_USE_CUDNN=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_plm_rsh_no_tree_spawn=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:TRAINING_JOB_ARN=arn:aws:sagemaker:ap-southeast-1:393782509758:training-job/mask-rcnn-s3-2020-04-02-10-49-58-217\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PYTHONUNBUFFERED=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_COMM_WORLD_LOCAL_SIZE=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SAGEMAKER_METRICS_DIRECTORY=/opt/ml/output/metrics/sagemaker\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=/v2/credentials/3a9ea992-0c59-4b02-8a34-6dbcf3a3bed6\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:TF_CPP_MIN_LOG_LEVEL=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:AWS_EXECUTION_ENV=AWS_ECS_EC2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_shmem_RUNTIME_QUERY_hint=mmap\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_UNIVERSE_SIZE=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:CUDA_VERSION=10.0.130\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_orte_local_daemon_uri=2538799104.0;tcp://10.0.98.32:50931\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_HP_BATCH_SIZE_PER_GPU=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_HP_IMAGES_PER_EPOCH=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:HFI_NO_BACKTRACE=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_initial_wdir=/mask-rcnn-tensorflow\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_SERVER_URI2=2538799104.0;tcp4://127.0.0.1:60543\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_DSTORE_ESH_BASE_PATH=/tmp/ompi.ip-10-0-98-32.0/pid.34/pmix_dstor_ds12_34\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PYTHONDONTWRITEBYTECODE=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_SERVER_URI3=2538799104.0;tcp4://127.0.0.1:60543\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:TF_SYNC_ON_FINISH=0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NVIDIA_REQUIRE_CUDA=cuda>=10.0 brand=tesla,driver>=384,driver<385 brand=tesla,driver>=410,driver<411\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:_=/usr/local/bin/mpirun.real\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_rmaps_base_mapping_policy=slot\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NVIDIA_DRIVER_CAPABILITIES=utility,compute\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_orte_ess_num_procs=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_COMM_WORLD_SIZE=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_norm\":\"FreezeBN\",\"batch_size_per_gpu\":1,\"eval_period\":1,\"images_per_epoch\":1,\"mode_fpn\":\"True\",\"mode_mask\":\"True\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"application/tfrecord\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mask-rcnn-s3-2020-04-02-10-49-58-217\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:ECS_CONTAINER_METADATA_URI=http://169.254.170.2/v3/980c1d8d-8049-4562-8a05-c2ca836fef2a\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_orte_ess_node_rank=0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:S3_REGION=\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_HP_EVAL_PERIOD=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PATH=/usr/loca[1,0]<stdout>:l/bin:/usr/local/nvidia/bin:/usr/local/openmpi/bin/:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_orte_tag_output=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_HP_BATCH_NORM=FreezeBN\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_BFROP_BUFFER_TYPE=PMIX_BFROP_BUFFER_NON_DESC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:TF_ENABLE_COND_V2=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_ARGV=/mask-rcnn-tensorflow/MaskRCNN/train.py --logdir /opt/ml/model --fp16 --throughput_log_freq=2000 --images_per_epoch 1 --config MODE_FPN=True MODE_MASK=True DATA.BASEDIR=/opt/ml/input/data/train BACKBONE.RESNET_NUM_BLOCKS=[3, 4, 6, 3] BACKBONE.WEIGHTS=/opt/ml/input/data/train/pretrained-models/ImageNet-R50-AlignPadding.npz BACKBONE.NORM=FreezeBN DATA.TRAIN=[\"train2017\"] DATA.VAL=(\"val2017\",) TRAIN.BATCH_SIZE_PER_GPU=1 TRAIN.EVAL_PERIOD=1 TRAIN.LR_EPOCH_SCHEDULE=[(16, 0.1), (20, 0.01), (24, None)] RPN.TOPK_PER_IMAGE=True PREPROC.PREDEFINED_PADDING=True TRAIN.GRADIENT_CLIP=0 TRAINER=horovod\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_HP_MODE_MASK=True\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:CUDA_PKG_VERSION=10-0=10.0.130-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:DMLC_INTERFACE=eth0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_SECURITY_MODE=native\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:TF_GPU_THREAD_MODE=gpu_private\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:HOROVOD_CYCLE_TIME=0.5\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:LANG=C.UTF-8\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_HPS={\"batch_norm\":\"FreezeBN\",\"batch_size_per_gpu\":1,\"eval_period\":1,\"images_per_epoch\":1,\"mode_fpn\":\"True\",\"mode_mask\":\"True\"}\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_orte_app_num=0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_orte_launch=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_SERVER_URI21=2538799104.0;tcp4://127.0.0.1:60543\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_ess_base_vpid=0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OPENCV_OPENCL_RUNTIME=disabled\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_PTL_MODULE=tcp,usock\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_orte_precondition_transports=20862b76442d02ba-4464b44c3ac19ae4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:TF_ENABLE_WINOGRAD_NONFUSED=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_mpi_yield_when_idle=0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_NUM_APP_CTX=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_HP_MODE_FPN=True\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:AWS_REGION=ap-southeast-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:TF_ENABLE_WHILE_V2=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_oob_tcp_if_include=eth0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_orte_hnp_uri=2538799104.0;tcp://10.0.98.32:50931\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SAGEMAKER_JOB_NAME=\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:S3_USE_HTTPS=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_btl_tcp_if_include=eth0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_orte_abort_on_non_zero_status=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_orte_output_filename=/opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_ess_base_jobid=2538799105\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_btl=^openib\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PMIX_SERVER_TMPDIR=/tmp/ompi.ip-10-0-98-32.0/pid.34\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_COMM_WORLD_LOCAL_RANK=0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_hwloc_base_binding_policy=none\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:TRAINING_JOB_NAME=mask-rcnn-s3-2020-04-02-10-49-58-217\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:LC_ALL=C.UTF-8\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PWD=/mask-rcnn-tensorflow\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:IPATH_NO_BACKTRACE=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_COMMAND=python3.6\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SAGEMAKER_TRAINING_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:OMPI_MCA_orte_top_session_dir=/tmp/ompi.ip-10-0-98-32.0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SAGEMAKER_REGION=\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages:/mask-rcnn-tensorflow\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:TENSORPACK_FP16=1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:SM_USER_ARGS=[\"--batch_norm\",\"FreezeBN\",\"--batch_size_per_gpu\",\"1\",\"--eval_period\",\"1\",\"--images_per_epoch\",\"1\",\"--mode_fpn\",\"True\",\"--mode_mask\",\"True\"]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NVIDIA_VISIBLE_DEVICES=all\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:HOROVOD_FUSION_THRESHOLD=67108864\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:TF_AUTOTUNE_THRESHOLD=2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @train.py:121]#033[0m ps -elf | grep mpirun\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @train.py:122]#033[0m 0 S root        32    29  0  80   0 -  1127 -      10:54 ?        00:00:00 /bin/sh -c HOROVOD_CYCLE_TIME=0.5 \\ HOROVOD_FUSION_THRESHOLD=67108864 \\ mpirun -np 1 \\ --host algo-1:1 \\ --allow-run-as-root \\ --display-map \\ --tag-output \\ -mca btl_tcp_if_include eth0 \\ -mca oob_tcp_if_include eth0 \\ -x NCCL_SOCKET_IFNAME=eth0 \\ --mca plm_rsh_no_tree_spawn 1 \\ -bind-to none -map-by slot \\ -mca pml ob1 -mca btl ^openib \\ -mca orte_abort_on_non_zero_status 1 \\ -x TENSORPACK_FP16=1 \\ -x NCCL_MIN_NRINGS=8 -x NCCL_DEBUG=INFO \\ -x HOROVOD_CYCLE_TIME -x HOROVOD_FUSION_THRESHOLD \\ -x LD_LIBRARY_PATH -x PATH \\ --output-filename /opt/ml/model  \\ /usr/local/bin/python3.6 /mask-rcnn-tensorflow/MaskRCNN/train.py --logdir /opt/ml/model --fp16 --throughput_log_freq=2000 --images_per_epoch 1 --config MODE_FPN=True MODE_MASK=True DATA.BASEDIR=/opt/ml/input/data/train BACKBONE.RESNET_NUM_BLOCKS='[3, 4, 6, 3]' BACKBONE.WEIGHTS=/opt/ml/input/data/train/pretrained-models/ImageNet-R50-AlignPadding.npz BACKBONE.NORM=FreezeBN DATA.TRAIN='[\"train2017\"]' DATA.VAL='(\"val2017\",)' TRAIN.BATCH_SIZE_PER_GPU=1 TRAIN.EVAL_PERIOD=1 TRAIN.LR_EPOCH_SCHEDULE='[(16, 0.1), (20, 0.01), (24, None)]' RPN.TOPK_PER_IMAGE=True PREPROC.PREDEFINED_PADDING=True TRAIN.GRADIENT_CLIP=0 TRAINER=horovod\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:0 S root        33    32  0  80   0 -  4952 -      10:54 ?        00:00:00 /bin/bash /usr/local/bin/mpirun -np 1 --host algo-1:1 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -x NCCL_SOCKET_IFNAME=eth0 --mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -x TENSORPACK_FP16=1 -x NCCL_MIN_NRINGS=8 -x NCCL_DEBUG=INFO -x HOROVOD_CYCLE_TIME -x HOROVOD_FUSION_THRESHOLD -x LD_LIBRARY_PATH -x PATH --output-filename /opt/ml/model /usr/local/bin/python3.6 /mask-rcnn-tensorflow/MaskRCNN/train.py --logdir /opt/ml/model --fp16 --throughput_log_freq=2000 --images_per_epoch 1 --config MODE_FPN=True MODE_MASK=True DATA.BASEDIR=/opt/ml/input/data/train BACKBONE.RESNET_NUM_BLOCKS=[3, 4, 6, 3] BACKBONE.WEIGHTS=/opt/ml/input/data/train/pretrained-models/ImageNet-R50-AlignPadding.npz BACKBONE.NORM=FreezeBN DATA.TRAIN=[\"train2017\"] DATA.VAL=(\"val2017\",) TRAIN.BATCH_SIZE_PER_GPU=1 TRAIN.EVAL_PERIOD=1 TRAIN.LR_EPOCH_SCHEDULE=[(16, 0.1), (20, 0.01), (24, None)] RPN.TOPK_PER_IMAGE=True PREPROC.PREDEFINED_PADDING=True TRAIN.GRADIENT_CLIP=0 TRAINER=horovod\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:0 S root        34    33  0  80   0 - 94269 SyS_po 10:54 ?        00:00:00 mpirun.real --allow-run-as-root -np 1 --host algo-1:1 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -x NCCL_SOCKET_IFNAME=eth0 --mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -x TENSORPACK_FP16=1 -x NCCL_MIN_NRINGS=8 -x NCCL_DEBUG=INFO -x HOROVOD_CYCLE_TIME -x HOROVOD_FUSION_THRESHOLD -x LD_LIBRARY_PATH -x PATH --output-filename /opt/ml/model /usr/local/bin/python3.6 /mask-rcnn-tensorflow/MaskRCNN/train.py --logdir /opt/ml/model --fp16 --throughput_log_freq=2000 --images_per_epoch 1 --config MODE_FPN=True MODE_MASK=True DATA.BASEDIR=/opt/ml/input/data/train BACKBONE.RESNET_NUM_BLOCKS=[3, 4, 6, 3] BACKBONE.WEIGHTS=/opt/ml/input/data/train/pretrained-models/ImageNet-R50-AlignPadding.npz BACKBONE.NORM=FreezeBN DATA.TRAIN=[\"train2017\"] DATA.VAL=(\"val2017\",) TRAIN.BATCH_SIZE_PER_GPU=1 TRAIN.EVAL_PERIOD=1 TRAIN.LR_EPOCH_SCHEDULE=[(16, 0.1), (20, 0.01), (24, None)] RPN.TOPK_PER_IMAGE=True PREPROC.PREDEFINED_PADDING=True TRAIN.GRADIENT_CLIP=0 TRAINER=horovod\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:0 S root        71    39  0  80   0 -  1127 -      10:54 ?        00:00:00 /bin/sh -c ps -elf | grep mpirun\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:0 S root        73    71  0  80   0 -  3248 -      10:54 ?        00:00:00 grep mpirun\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @config.py:257]#033[0m #033[5m#033[31mWRN#033[0m It's not recommended to use horovod for single-machine training. Replicated trainer is more stable and has the same efficiency.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @config.py:278]#033[0m Config: ------------------------------------------\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:{'BACKBONE': {'FREEZE_AFFINE': False,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              'FREEZE_AT': 2,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              'NORM': 'FreezeBN',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              'RESNET_NUM_BLOCKS': [3, 4, 6, 3],\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              'STRIDE_1X1': False,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              'TF_PAD_MODE': False,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:              'WEIGHTS': '/opt/ml/input/data/train/pretrained-models/ImageNet-R50-AlignPadding.npz'},\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'DATA': {'BASEDIR': '/opt/ml/input/data/train',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:          'CLASS_NAMES': ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                          'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                          'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                          'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                          'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                          'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                          'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                          'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                          'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                          'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                          'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                          'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                          'hair drier', 'toothbrush'],\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:          'NUM_CATEGORY': 80,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:          'NUM_CLASS': 81,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:          'TRAIN': ['train2017'],\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:          'VAL': ('val2017',)},\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'FPN': {'ANCHOR_STRIDES': (4, 8, 16, 32, 64),\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'BOXCLASS_CONV_HEAD_DIM': 256,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'BOXCLASS_FC_HEAD_DIM': 1024,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'BOXCLASS_HEAD_FUNC': 'boxclass_2fc_head',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'MRCNN_HEAD_FUNC': 'maskrcnn_up4conv_head',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'NORM': 'None',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'NUM_CHANNEL': 256,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'PROPOSAL_MODE': 'Level',\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'RESOLUTION_REQUIREMENT': 32},\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'FRCNN': {'BATCH_PER_IM': 512,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:           'BBOX_REG_WEIGHTS': [10.0, 10.0, 5.0, 5.0],\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:           'FG_RATIO': 0.25,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:           'FG_THRESH': 0.5},\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'MODE_FPN': True,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'MODE_MASK': True,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'MRCNN': {'HEAD_DIM': 256},\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'PREPROC': {'MAX_SIZE': 1344.0,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:             'PADDING_SHAPES': [(800, 1000), (800, 1200), (800, 1350)],\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:             'PIXEL_MEAN': [123.675, 116.28, 103.53],\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:             'PIXEL_STD': [58.395, 57.12, 57.375],\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:             'PREDEFINED_PADDING': True,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:             'TEST_SHORT_EDGE_SIZE': 800,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:             'TRAIN_SHORT_EDGE_SIZE': [800, 800]},\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'RPN': {'ANCHOR_RATIOS': (0.5, 1.0, 2.0),\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'ANCHOR_SIZES': (32, 64, 128, 256, 512),\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'ANCHOR_STRIDE': 16,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'BATCH_PER_IM': 256,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'CROWD_OVERLAP_THRESH': 9.99,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'FG_RATIO': 0.5,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'HEAD_DIM': 1024,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'MIN_SIZE': 0.1,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'NEGATIVE_ANCHOR_THRESH': 0.3,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'NUM_ANCHOR': 15,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'POSITIVE_ANCHOR_THRESH': 0.7,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'PROPOSAL_NMS_THRESH': 0.7,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'SLOW_ACCURATE_MASK': True,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'TEST_PER_LEVEL_NMS_TOPK': 1000,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'TEST_POST_NMS_TOPK': 1000,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'TEST_PRE_NMS_TOPK': 6000,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'TOPK_PER_IMAGE': True,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'TRAIN_PER_LEVEL_NMS_TOPK': 2000,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'TRAIN_POST_NMS_TOPK': 2000,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'TRAIN_PRE_NMS_TOPK': 12000,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:         'UNQUANTIZED_ANCHOR': True},\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'TEST': {'FRCNN_NMS_THRESH': 0.5,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:          'RESULTS_PER_IM': 100,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:          'RESULT_SCORE_THRESH': 0.05,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:          'RESULT_SCORE_THRESH_VIS': 0.3},\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'TRAIN': {'BASE_LR': 0.00125,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:           'BATCH_SIZE_PER_GPU': 1,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:           'EVAL_PERIOD': 1,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:           'GRADIENT_CLIP': 0,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:           'LR_EPOCH_SCHEDULE': [(16, 0.1), (20, 0.01), (24, None)],\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:           'NUM_GPUS': 1,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:           'SEED': 1234,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:           'STARTING_EPOCH': 1,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:           'WARMUP_INIT_LR': 0.00041250000000000005,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:           'WARMUP_STEPS': 1000,\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:           'WEIGHT_DECAY': 0.0001},\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>: 'TRAINER': 'horovod'}\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @train.py:249]#033[0m Warm Up Schedule (steps, value): [(0, 0.0033000000000000004), (1000, 0.00125)]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @train.py:250]#033[0m LR Schedule (epochs, value): [(1000, 0.00125), (16, 0.000125), (20, 1.25e-05)]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:In train dataflow\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_train2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @timer.py:50]#033[0m Load Groundtruth Boxes for train2017 finished, time:0.0016sec.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done loading roidbs\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:34 @data.py:509]#033[0m Filtered 0 images which contain no non-crowd groudtruth boxes. Total #images for training: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Batching roidbs\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done batching roidbs\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @trainers.py:393]#033[0m [HorovodTrainer] local rank=0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @input_source.py:222]#033[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m conv0 input: [None, 3, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m conv0 output: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m pool0 input: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m pool0 output: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group0/block0/conv1 input: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m group0/block0/conv1 output: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group0/block0/conv2 input: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m group0/block0/conv2 output: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group0/block0/conv3 input: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m group0/block0/conv3 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group0/block0/convshortcut input: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m group0/block0/convshortcut output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group0/block1/conv1 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m group0/block1/conv1 output: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group0/block1/conv2 input: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m group0/block1/conv2 output: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group0/block1/conv3 input: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m group0/block1/conv3 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group0/block2/conv1 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m group0/block2/conv1 output: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group0/block2/conv2 input: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m group0/block2/conv2 output: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group0/block2/conv3 input: [None, 64, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m group0/block2/conv3 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group1/block0/conv1 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m group1/block0/conv1 output: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group1/block0/conv2 input: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m group1/block0/conv2 output: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group1/block0/conv3 input: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m group1/block0/conv3 output: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group1/block0/convshortcut input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:135]#033[0m group1/block0/convshortcut output: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:35 @registry.py:127]#033[0m group1/block1/conv1 input: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group1/block1/conv1 output: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group1/block1/conv2 input: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group1/block1/conv2 output: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group1/block1/conv3 input: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group1/block1/conv3 output: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group1/block2/conv1 input: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group1/block2/conv1 output: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group1/block2/conv2 input: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group1/block2/conv2 output: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group1/block2/conv3 input: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group1/block2/conv3 output: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group1/block3/conv1 input: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group1/block3/conv1 output: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group1/block3/conv2 input: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group1/block3/conv2 output: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group1/block3/conv3 input: [None, 128, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group1/block3/conv3 output: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group2/block0/conv1 input: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group2/block0/conv1 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group2/block0/conv2 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group2/block0/conv2 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group2/block0/conv3 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group2/block0/conv3 output: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group2/block0/convshortcut input: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group2/block0/convshortcut output: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group2/block1/conv1 input: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group2/block1/conv1 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group2/block1/conv2 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group2/block1/conv2 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group2/block1/conv3 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group2/block1/conv3 output: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group2/block2/conv1 input: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group2/block2/conv1 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group2/block2/conv2 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group2/block2/conv2 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group2/block2/conv3 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:135]#033[0m group2/block2/conv3 output: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:36 @registry.py:127]#033[0m group2/block3/conv1 input: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group2/block3/conv1 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group2/block3/conv2 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group2/block3/conv2 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group2/block3/conv3 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group2/block3/conv3 output: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group2/block4/conv1 input: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group2/block4/conv1 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group2/block4/conv2 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group2/block4/conv2 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group2/block4/conv3 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group2/block4/conv3 output: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group2/block5/conv1 input: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group2/block5/conv1 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group2/block5/conv2 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group2/block5/conv2 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group2/block5/conv3 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group2/block5/conv3 output: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group3/block0/conv1 input: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group3/block0/conv1 output: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group3/block0/conv2 input: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group3/block0/conv2 output: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group3/block0/conv3 input: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group3/block0/conv3 output: [None, 2048, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group3/block0/convshortcut input: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group3/block0/convshortcut output: [None, 2048, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group3/block1/conv1 input: [None, 2048, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group3/block1/conv1 output: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group3/block1/conv2 input: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group3/block1/conv2 output: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group3/block1/conv3 input: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group3/block1/conv3 output: [None, 2048, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group3/block2/conv1 input: [None, 2048, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:135]#033[0m group3/block2/conv1 output: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @registry.py:127]#033[0m group3/block2/conv2 input: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:37 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m group3/block2/conv2 output: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m group3/block2/conv3 input: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @batch_norm.py:166]#033[0m #033[5m#033[31mWRN#033[0m [BatchNorm] Using moving_mean/moving_variance in training.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m group3/block2/conv3 output: [None, 2048, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:c2345 (<tf.Tensor 'group0/block2/output:0' shape=(?, 256, ?, ?) dtype=float16>, <tf.Tensor 'group1/block3/output:0' shape=(?, 512, ?, ?) dtype=float16>, <tf.Tensor 'group2/block5/output:0' shape=(?, 1024, ?, ?) dtype=float16>, <tf.Tensor 'group3/block2/output:0' shape=(?, 2048, ?, ?) dtype=float16>)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m fpn input: [None, 256, None, None],[None, 512, None, None],[None, 1024, None, None],[None, 2048, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m fpn/lateral_1x1_c2 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m fpn/lateral_1x1_c2 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m fpn/lateral_1x1_c3 input: [None, 512, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m fpn/lateral_1x1_c3 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m fpn/lateral_1x1_c4 input: [None, 1024, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m fpn/lateral_1x1_c4 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m fpn/lateral_1x1_c5 input: [None, 2048, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m fpn/lateral_1x1_c5 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m fpn/upsample_lat5 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m fpn/upsample_lat5 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m fpn/upsample_lat4 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m fpn/upsample_lat4 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m fpn/upsample_lat3 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m fpn/upsample_lat3 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m fpn/posthoc_3x3_p2 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m fpn/posthoc_3x3_p2 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m fpn/posthoc_3x3_p3 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m fpn/posthoc_3x3_p3 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m fpn/posthoc_3x3_p4 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m fpn/posthoc_3x3_p4 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m fpn/posthoc_3x3_p5 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m fpn/posthoc_3x3_p5 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m fpn/maxpool_p6 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m fpn/maxpool_p6 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m fpn output: [None, 256, None, None],[None, 256, None, None],[None, 256, None, None],[None, 256, None, None],[None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m rpn input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m rpn/conv0 input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m rpn/conv0 output: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m rpn/class input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m rpn/class output: [None, 3, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:127]#033[0m rpn/box input: [None, 256, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m rpn/box output: [None, 12, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:38 @registry.py:135]#033[0m rpn output: [None, None, None, 3],[None, 12, None, None]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:40 @registry.py:127]#033[0m fastrcnn input: [None, 256, 7, 7]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:40 @registry.py:127]#033[0m fastrcnn/fc6 input: [None, 256, 7, 7]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:40 @registry.py:135]#033[0m fastrcnn/fc6 output: [None, 1024]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:40 @registry.py:127]#033[0m fastrcnn/fc7 input: [None, 1024]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:40 @registry.py:135]#033[0m fastrcnn/fc7 output: [None, 1024]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:40 @registry.py:135]#033[0m fastrcnn output: [None, 1024]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:40 @registry.py:127]#033[0m fastrcnn/outputs input: [None, 1024]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:40 @registry.py:127]#033[0m fastrcnn/outputs/class input: [None, 1024]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:40 @registry.py:135]#033[0m fastrcnn/outputs/class output: [None, 81]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:40 @registry.py:127]#033[0m fastrcnn/outputs/box input: [None, 1024]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:40 @registry.py:135]#033[0m fastrcnn/outputs/box output: [None, 324]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:40 @registry.py:135]#033[0m fastrcnn/outputs output: [None, 81],[None, 81, 4]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @registry.py:127]#033[0m maskrcnn input: [None, 256, 14, 14]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @registry.py:127]#033[0m maskrcnn/fcn0 input: [None, 256, 14, 14]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @registry.py:135]#033[0m maskrcnn/fcn0 output: [None, 256, 14, 14]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @registry.py:127]#033[0m maskrcnn/fcn1 input: [None, 256, 14, 14]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @registry.py:135]#033[0m maskrcnn/fcn1 output: [None, 256, 14, 14]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @registry.py:127]#033[0m maskrcnn/fcn2 input: [None, 256, 14, 14]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @registry.py:135]#033[0m maskrcnn/fcn2 output: [None, 256, 14, 14]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @registry.py:127]#033[0m maskrcnn/fcn3 input: [None, 256, 14, 14]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @registry.py:135]#033[0m maskrcnn/fcn3 output: [None, 256, 14, 14]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @registry.py:127]#033[0m maskrcnn/deconv input: [None, 256, 14, 14]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @registry.py:135]#033[0m maskrcnn/deconv output: [None, 256, 28, 28]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @registry.py:127]#033[0m maskrcnn/conv input: [None, 256, 28, 28]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @registry.py:135]#033[0m maskrcnn/conv output: [None, 80, 28, 28]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @registry.py:135]#033[0m maskrcnn output: [None, 80, 28, 28]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @regularize.py:97]#033[0m regularize_cost() found 63 variables to regularize.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:41 @regularize.py:22]#033[0m The following tensors will be regularized: group1/block0/conv1/W:0, group1/block0/conv2/W:0, group1/block0/conv3/W:0, group1/block0/convshortcut/W:0, group1/block1/conv1/W:0, group1/block1/conv2/W:0, group1/block1/conv3/W:0, group1/block2/conv1/W:0, group1/block2/conv2/W:0, group1/block2/conv3/W:0, group1/block3/conv1/W:0, group1/block3/conv2/W:0, group1/block3/conv3/W:0, group2/block0/conv1/W:0, group2/block0/conv2/W:0, group2/block0/conv3/W:0, group2/block0/convshortcut/W:0, group2/block1/conv1/W:0, group2/block1/conv2/W:0, group2/block1/conv3/W:0, group2/block2/conv1/W:0, group2/block2/conv2/W:0, group2/block2/conv3/W:0, group2/block3/conv1/W:0, group2/block3/conv2/W:0, group2/block3/conv3/W:0, group2/block4/conv1/W:0, group2/block4/conv2/W:0, group2/block4/conv3/W:0, group2/block5/conv1/W:0, group2/block5/conv2/W:0, group2/block5/conv3/W:0, group3/block0/conv1/W:0, group3/block0/conv2/W:0, group3/block0/conv3/W:0, group3/block0/convshortcut/W:0, group3/block1/conv1/W:0, group3/block1/conv2/W:0, group3/block1/conv3/W:0, group3/block2/conv1/W:0, group3/block2/conv2/W:0, group3/block2/conv3/W:0, fpn/lateral_1x1_c2/W:0, fpn/lateral_1x1_c3/W:0, fpn/lateral_1x1_c4/W:0, fpn/lateral_1x1_c5/W:0, fpn/posthoc_3x3_p2/W:0, fpn/posthoc_3x3_p3/W:0, fpn/posthoc_3x3_p4/W:0, fpn/posthoc_3x3_p5/W:0, rpn/conv0/W:0, rpn/class/W:0, rpn/box/W:0, fastrcnn/fc6/W:0, fastrcnn/fc7/W:0, fastrcnn/outputs/class/W:0, fastrcnn/outputs/box/W:0, maskrcnn/fcn0/W:0, maskrcnn/fcn1/W:0, maskrcnn/fcn2/W:0, maskrcnn/fcn3/W:0, maskrcnn/deconv/W:0, maskrcnn/conv/W:0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:TENSORPACK_FP16 set. Using FP16 loss scaling of 1024.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:47 @model_utils.py:66]#033[0m #033[36mTrainable Variables:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[0mname                                   shape                    dim\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:-------------------------------------  ------------------  --------\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block0/conv1/W:0                [1, 1, 256, 128]       32768\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block0/conv1/bn/gamma:0         [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block0/conv1/bn/beta:0          [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block0/conv2/W:0                [3, 3, 128, 128]      147456\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block0/conv2/bn/gamma:0         [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block0/conv2/bn/beta:0          [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block0/conv3/W:0                [1, 1, 128, 512]       65536\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block0/conv3/bn/gamma:0         [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block0/conv3/bn/beta:0          [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block0/convshortcut/W:0         [1, 1, 256, 512]      131072\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block0/convshortcut/bn/gamma:0  [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block0/convshortcut/bn/beta:0   [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block1/conv1/W:0                [1, 1, 512, 128]       65536\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block1/conv1/bn/gamma:0         [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block1/conv1/bn/beta:0          [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block1/conv2/W:0                [3, 3, 128, 128]      147456\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block1/conv2/bn/gamma:0         [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block1/conv2/bn/beta:0          [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block1/conv3/W:0                [1, 1, 128, 512]       65536\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block1/conv3/bn/gamma:0         [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block1/conv3/bn/beta:0          [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block2/conv1/W:0                [1, 1, 512, 128]       65536\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block2/conv1/bn/gamma:0         [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block2/conv1/bn/beta:0          [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block2/conv2/W:0                [3, 3, 128, 128]      147456\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block2/conv2/bn/gamma:0         [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block2/conv2/bn/beta:0          [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block2/conv3/W:0                [1, 1, 128, 512]       65536\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block2/conv3/bn/gamma:0         [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block2/conv3/bn/beta:0          [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block3/conv1/W:0                [1, 1, 512, 128]       65536\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block3/conv1/bn/gamma:0         [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block3/conv1/bn/beta:0          [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block3/conv2/W:0                [3, 3, 128, 128]      147456\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block3/conv2/bn/gamma:0         [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block3/conv2/bn/beta:0          [128]                    128\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block3/conv3/W:0                [1, 1, 128, 512]       65536\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block3/conv3/bn/gamma:0         [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group1/block3/conv3/bn/beta:0          [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block0/conv1/W:0                [1, 1, 512, 256]      131072\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block0/conv1/bn/gamma:0         [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block0/conv1/bn/beta:0          [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block0/conv2/W:0                [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block0/conv2/bn/gamma:0         [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block0/conv2/bn/beta:0          [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block0/conv3/W:0                [1, 1, 256, 1024]     262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block0/conv3/bn/gamma:0         [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block0/conv3/bn/beta:0          [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block0/convshortcut/W:0         [1, 1, 512, 1024]     524288\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block0/convshortcut/bn/gamma:0  [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block0/convshortcut/bn/beta:0   [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block1/conv1/W:0                [1, 1, 1024, 256]     262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block1/conv1/bn/gamma:0         [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block1/conv1/bn/beta:0          [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block1/conv2/W:0                [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block1/conv2/bn/gamma:0         [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block1/conv2/bn/beta:0          [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/b[1,0]<stdout>:lock1/conv3/W:0                [1, 1, 256, 1024]     262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block1/conv3/bn/gamma:0         [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block1/conv3/bn/beta:0          [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block2/conv1/W:0                [1, 1, 1024, 256]     262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block2/conv1/bn/gamma:0         [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block2/conv1/bn/beta:0          [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block2/conv2/W:0                [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block2/conv2/bn/gamma:0         [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block2/conv2/bn/beta:0          [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block2/conv3/W:0                [1, 1, 256, 1024]     262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block2/conv3/bn/gamma:0         [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block2/conv3/bn/beta:0          [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block3/conv1/W:0                [1, 1, 1024, 256]     262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block3/conv1/bn/gamma:0         [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block3/conv1/bn/beta:0          [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block3/conv2/W:0                [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block3/conv2/bn/gamma:0         [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block3/conv2/bn/beta:0          [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block3/conv3/W:0                [1, 1, 256, 1024]     262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block3/conv3/bn/gamma:0         [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block3/conv3/bn/beta:0          [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block4/conv1/W:0                [1, 1, 1024, 256]     262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block4/conv1/bn/gamma:0         [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block4/conv1/bn/beta:0          [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block4/conv2/W:0                [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block4/conv2/bn/gamma:0         [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block4/conv2/bn/beta:0          [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block4/conv3/W:0                [1, 1, 256, 1024]     262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block4/conv3/bn/gamma:0         [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block4/conv3/bn/beta:0          [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block5/conv1/W:0                [1, 1, 1024, 256]     262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block5/conv1/bn/gamma:0         [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block5/conv1/bn/beta:0          [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block5/conv2/W:0                [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block5/conv2/bn/gamma:0         [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block5/conv2/bn/beta:0          [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block5/conv3/W:0                [1, 1, 256, 1024]     262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block5/conv3/bn/gamma:0         [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group2/block5/conv3/bn/beta:0          [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block0/conv1/W:0                [1, 1, 1024, 512]     524288\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block0/conv1/bn/gamma:0         [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block0/conv1/bn/beta:0          [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block0/conv2/W:0                [3, 3, 512, 512]     2359296\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block0/conv2/bn/gamma:0         [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block0/conv2/bn/beta:0          [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block0/conv3/W:0                [1, 1, 512, 2048]    1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block0/conv3/bn/gamma:0         [2048]                  2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block0/conv3/bn/beta:0          [2048]                  2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block0/convshortcut/W:0         [1, 1, 1024, 2048]   2097152\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block0/convshortcut/bn/gamma:0  [2048]                  2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block0/convshortcut/bn/beta:0   [2048]                  2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block1/conv1/W:0                [1, 1, 2048, 512]    1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block1/conv1/bn/gamma:0         [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block1/conv1/bn/beta:0          [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block1/conv2/W:0                [3, 3, 512, 512]     2359296\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block1/conv2/bn/gamma:0         [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block1/conv2/bn/beta:0          [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block1/conv3/W:0                [1, 1, 512, 2048]    1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block1/conv3/bn/gamma:0         [2048]                  2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block1/conv3/bn/beta:0          [2048]                  2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block2/conv1/W:0[1,0]<stdout>:                [1, 1, 2048, 512]    1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block2/conv1/bn/gamma:0         [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block2/conv1/bn/beta:0          [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block2/conv2/W:0                [3, 3, 512, 512]     2359296\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block2/conv2/bn/gamma:0         [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block2/conv2/bn/beta:0          [512]                    512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block2/conv3/W:0                [1, 1, 512, 2048]    1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block2/conv3/bn/gamma:0         [2048]                  2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:group3/block2/conv3/bn/beta:0          [2048]                  2048\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/lateral_1x1_c2/W:0                 [1, 1, 256, 256]       65536\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/lateral_1x1_c2/b:0                 [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/lateral_1x1_c3/W:0                 [1, 1, 512, 256]      131072\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/lateral_1x1_c3/b:0                 [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/lateral_1x1_c4/W:0                 [1, 1, 1024, 256]     262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/lateral_1x1_c4/b:0                 [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/lateral_1x1_c5/W:0                 [1, 1, 2048, 256]     524288\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/lateral_1x1_c5/b:0                 [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/posthoc_3x3_p2/W:0                 [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/posthoc_3x3_p2/b:0                 [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/posthoc_3x3_p3/W:0                 [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/posthoc_3x3_p3/b:0                 [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/posthoc_3x3_p4/W:0                 [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/posthoc_3x3_p4/b:0                 [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/posthoc_3x3_p5/W:0                 [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fpn/posthoc_3x3_p5/b:0                 [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:rpn/conv0/W:0                          [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:rpn/conv0/b:0                          [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:rpn/class/W:0                          [1, 1, 256, 3]           768\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:rpn/class/b:0                          [3]                        3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:rpn/box/W:0                            [1, 1, 256, 12]         3072\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:rpn/box/b:0                            [12]                      12\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fastrcnn/fc6/W:0                       [12544, 1024]       12845056\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fastrcnn/fc6/b:0                       [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fastrcnn/fc7/W:0                       [1024, 1024]         1048576\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fastrcnn/fc7/b:0                       [1024]                  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fastrcnn/outputs/class/W:0             [1024, 81]             82944\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fastrcnn/outputs/class/b:0             [81]                      81\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fastrcnn/outputs/box/W:0               [1024, 324]           331776\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:fastrcnn/outputs/box/b:0               [324]                    324\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:maskrcnn/fcn0/W:0                      [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:maskrcnn/fcn0/b:0                      [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:maskrcnn/fcn1/W:0                      [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:maskrcnn/fcn1/b:0                      [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:maskrcnn/fcn2/W:0                      [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:maskrcnn/fcn2/b:0                      [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:maskrcnn/fcn3/W:0                      [3, 3, 256, 256]      589824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:maskrcnn/fcn3/b:0                      [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:maskrcnn/deconv/W:0                    [2, 2, 256, 256]      262144\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:maskrcnn/deconv/b:0                    [256]                    256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:maskrcnn/conv/W:0                      [1, 1, 256, 80]        20480\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:maskrcnn/conv/b:0                      [80]                      80#033[36m\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Total #vars=168, #params=44175092, size=168.51MB#033[0m\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:47 @base.py:210]#033[0m Setup callbacks graph ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:48 @tower.py:134]#033[0m Building graph for predict tower 'tower-pred-0' on device /gpu:0 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:c2345 (<tf.Tensor 'tower-pred-0/group0/block2/output:0' shape=(?, 256, ?, ?) dtype=float16>, <tf.Tensor 'tower-pred-0/group1/block3/output:0' shape=(?, 512, ?, ?) dtype=float16>, <tf.Tensor 'tower-pred-0/group2/block5/output:0' shape=(?, 1024, ?, ?) dtype=float16>, <tf.Tensor 'tower-pred-0/group3/block2/output:0' shape=(?, 2048, ?, ?) dtype=float16>)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:52 @collection.py:153]#033[0m Size of these collections were changed in tower-pred-0: (tf.GraphKeys.MODEL_VARIABLES: 183->238)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:52 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:52 @timer.py:50]#033[0m Load Groundtruth Boxes for val2017 finished, time:0.0032sec.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:52 @summary.py:48]#033[0m [MovingAverageSummary] 27 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:52 @summary.py:95]#033[0m Summarizing collection 'summaries' of size 30.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:54:57 @base.py:231]#033[0m Creating the session ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:03 @base.py:237]#033[0m Initializing the session ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:03 @sessinit.py:206]#033[0m Variables to restore from dict: group2/block4/conv3/bn/beta:0, group2/block4/conv2/bn/gamma:0, group1/block2/conv3/bn/variance/EMA:0, group0/block0/conv1/bn/variance/EMA:0, group2/block3/conv2/bn/beta:0, group2/block4/conv3/bn/gamma:0, group2/block4/conv3/bn/variance/EMA:0, group1/block0/conv2/bn/mean/EMA:0, group2/block3/conv2/bn/variance/EMA:0, group1/block0/convshortcut/bn/beta:0, group2/block5/conv3/bn/variance/EMA:0, group3/block2/conv2/bn/variance/EMA:0, group0/block0/conv3/W:0, group2/block0/convshortcut/bn/gamma:0, group3/block1/conv1/bn/variance/EMA:0, group0/block0/conv3/bn/gamma:0, group1/block2/conv1/bn/beta:0, group2/block0/conv1/bn/mean/EMA:0, group0/block0/conv1/W:0, group3/block0/conv1/W:0, group1/block3/conv3/W:0, group0/block0/conv3/bn/variance/EMA:0, group1/block0/conv2/W:0, group2/block3/conv3/bn/mean/EMA:0, group3/block0/conv1/bn/mean/EMA:0, group3/block2/conv3/bn/beta:0, group0/block1/conv3/bn/gamma:0, group0/block0/convshortcut/W:0, group2/block5/conv2/W:0, group1/block0/conv3/bn/variance/EMA:0, group2/block5/conv1/W:0, group2/block0/conv2/bn/gamma:0, group3/block2/conv1/bn/beta:0, group0/block1/conv3/bn/variance/EMA:0, group2/block0/conv3/bn/gamma:0, group1/block0/conv3/bn/beta:0, group2/block0/conv2/bn/beta:0, group1/block1/conv3/bn/gamma:0, group2/block1/conv2/bn/gamma:0, conv0/W:0, group2/block2/conv3/bn/variance/EMA:0, group0/block2/conv2/bn/beta:0, group3/block2/conv1/bn/gamma:0, group2/block5/conv1/bn/variance/EMA:0, group1/block3/conv1/bn/mean/EMA:0, group2/block2/conv2/W:0, group1/block0/convshortcut/bn/gamma:0, group1/block2/conv1/bn/variance/EMA:0, group0/block0/conv2/bn/variance/EMA:0, group1/block0/conv2/bn/gamma:0, group1/block2/conv3/bn/beta:0, group3/block0/conv2/W:0, group3/block1/conv1/W:0, group1/block0/conv3/W:0, group1/block1/conv1/bn/beta:0, group3/block0/conv3/bn/gamma:0, group1/block2/conv2/bn/beta:0, group1/block3/conv2/bn/gamma:0, group1/block0/convshortcut/bn/mean/EMA:0, group2/block4/conv2/W:0, group2/block1/conv1/bn/beta:0, group1/block0/convshortcut/bn/variance/EMA:0, group0/block0/conv3/bn/beta:0, group1/block3/conv3/bn/beta:0, group0/block0/conv1/bn/mean/EMA:0, group2/block4/conv3/bn/mean/EMA:0, group2/block1/conv3/bn/variance/EMA:0, group2/block3/conv1/bn/beta:0, group2/block1/conv2/bn/variance/EMA:0, group2/block3/conv2/bn/mean/EMA:0, group3/block1/conv3/bn/beta:0, group2/block2/conv2/bn/gamma:0, group2/block4/conv1/bn/mean/EMA:0, group0/block1/conv1/bn/gamma:0, group3/block1/conv3/bn/gamma:0, group3/block0/convshortcut/bn/gamma:0, group1/block1/conv1/bn/variance/EMA:0, group2/block5/conv1/bn/mean/EMA:0, group3/block2/conv3/bn/variance/EMA:0, group2/block3/conv3/bn/gamma:0, group2/block4/conv2/bn/variance/EMA:0, group1/block3/conv3/bn/variance/EMA:0, group3/block0/conv2/bn/beta:0, group3/block0/conv2/bn/mean/EMA:0, group2/block1/conv2/bn/beta:0, group2/block2/conv1/bn/variance/EMA:0, group0/block0/conv1/bn/beta:0, group1/block1/conv2/W:0, group1/block3/conv1/bn/gamma:0, group2/block1/conv3/bn/gamma:0, group2/block2/conv3/bn/gamma:0, group2/block0/conv1/bn/beta:0, group2/block3/conv1/bn/gamma:0, group3/block0/convshortcut/bn/mean/EMA:0, group0/block1/conv2/bn/gamma:0, group3/block1/conv1/bn/gamma:0, group2/block5/conv3/bn/mean/EMA:0, group2/block0/conv3/bn/mean/EMA:0, group3/block2/conv2/W:0, group3/block1/conv2/W:0, group2/block5/conv2/bn/beta:0, group3/block0/conv1/bn/beta:0, group2/block0/conv3/W:0, group3/block0/conv2/bn/gamma:0, group1/block0/conv1/W:0, group0/block0/convshortcut/bn/gamma:0, group2/block0/conv1/W:0, group3/block1/conv1/bn/mean/EMA:0, group2/block2/conv1/W:0, group1/block1/conv2/bn/variance/EMA:0, conv0/bn/gamma:0, group1/block0/conv2/bn/variance/EMA:0, group0/block1/conv3/bn/mean/EMA:0, group1/block1/conv1/W:0, group0/block1/conv3/bn/beta:0, group2/block2/conv3/bn/mean/EMA:0, group0/block1/conv1/bn/variance/EMA:0, group0/block1/conv2/bn/mean/EMA:0, group1/block0/conv1/bn/beta:0, group0/block2/conv2/W:0, group2/block4/conv3/W:0, group1/block3/conv3/bn/mean/EMA:0, conv0/bn/mean/EMA:0, group2/block2/conv3[1,0]<stdout>:/W:0, group2/block3/conv2/bn/gamma:0, group1/block2/conv3/bn/gamma:0, group2/block5/conv1/bn/beta:0, group1/block3/conv2/bn/mean/EMA:0, group0/block2/conv1/bn/variance/EMA:0, group2/block4/conv1/bn/beta:0, group1/block2/conv3/bn/mean/EMA:0, group0/block1/conv1/bn/mean/EMA:0, group2/block2/conv2/bn/mean/EMA:0, group1/block0/conv1/bn/gamma:0, group2/block4/conv1/W:0, conv0/bn/variance/EMA:0, group0/block2/conv1/bn/mean/EMA:0, group2/block5/conv3/bn/gamma:0, group2/block0/convshortcut/bn/variance/EMA:0, group2/block1/conv3/bn/beta:0, group0/block2/conv2/bn/gamma:0, group1/block3/conv2/bn/beta:0, group2/block5/conv3/W:0, group1/block1/conv3/bn/mean/EMA:0, group1/block2/conv1/bn/gamma:0, group1/block1/conv1/bn/mean/EMA:0, group3/block2/conv1/W:0, group1/block0/conv3/bn/mean/EMA:0, group0/block2/conv1/bn/beta:0, group2/block3/conv3/bn/variance/EMA:0, group1/block2/conv1/W:0, group1/block2/conv2/W:0, group2/block2/conv1/bn/mean/EMA:0, group1/block0/convshortcut/W:0, group2/block0/conv2/W:0, group0/block2/conv1/bn/gamma:0, group0/block2/conv3/bn/beta:0, group1/block1/conv1/bn/gamma:0, group3/block0/conv1/bn/gamma:0, group2/block2/conv2/bn/variance/EMA:0, group3/block1/conv2/bn/gamma:0, group0/block1/conv1/W:0, group2/block5/conv2/bn/gamma:0, group2/block1/conv3/W:0, group3/block0/convshortcut/W:0, group1/block3/conv2/W:0, group2/block5/conv2/bn/variance/EMA:0, group0/block0/conv3/bn/mean/EMA:0, group3/block1/conv1/bn/beta:0, group3/block1/conv3/bn/mean/EMA:0, group1/block0/conv1/bn/mean/EMA:0, group2/block2/conv1/bn/gamma:0, group0/block1/conv2/bn/variance/EMA:0, group0/block0/convshortcut/bn/beta:0, group3/block1/conv2/bn/beta:0, group3/block2/conv2/bn/beta:0, group2/block3/conv3/W:0, group1/block1/conv3/bn/variance/EMA:0, group3/block0/conv1/bn/variance/EMA:0, group2/block0/conv1/bn/gamma:0, group1/block2/conv3/W:0, group3/block1/conv2/bn/variance/EMA:0, group3/block0/conv3/bn/beta:0, group0/block0/convshortcut/bn/mean/EMA:0, group2/block1/conv3/bn/mean/EMA:0, group1/block1/conv2/bn/mean/EMA:0, group3/block1/conv3/W:0, group1/block2/conv1/bn/mean/EMA:0, group2/block0/convshortcut/bn/mean/EMA:0, group0/block0/conv2/bn/beta:0, group0/block1/conv1/bn/beta:0, group3/block2/conv1/bn/mean/EMA:0, group3/block2/conv3/bn/gamma:0, group2/block3/conv1/bn/mean/EMA:0, group0/block0/conv2/W:0, group2/block3/conv3/bn/beta:0, group1/block2/conv2/bn/mean/EMA:0, group2/block0/conv2/bn/variance/EMA:0, group3/block0/conv3/bn/variance/EMA:0, group0/block1/conv2/W:0, group1/block0/conv2/bn/beta:0, conv0/bn/beta:0, group2/block4/conv1/bn/variance/EMA:0, group1/block0/conv3/bn/gamma:0, group2/block0/convshortcut/W:0, group0/block0/convshortcut/bn/variance/EMA:0, group0/block0/conv1/bn/gamma:0, group2/block1/conv1/bn/variance/EMA:0, group0/block1/conv2/bn/beta:0, group0/block1/conv3/W:0, group0/block0/conv2/bn/mean/EMA:0, group1/block1/conv2/bn/gamma:0, group1/block3/conv1/W:0, group2/block2/conv1/bn/beta:0, group2/block3/conv1/W:0, group0/block2/conv2/bn/variance/EMA:0, group2/block5/conv1/bn/gamma:0, group2/block2/conv3/bn/beta:0, group0/block2/conv1/W:0, group2/block4/conv2/bn/beta:0, group3/block2/conv3/W:0, group2/block1/conv1/bn/gamma:0, group1/block0/conv1/bn/variance/EMA:0, group3/block0/convshortcut/bn/beta:0, group0/block2/conv3/bn/mean/EMA:0, group0/block0/conv2/bn/gamma:0, group2/block0/convshortcut/bn/beta:0, group0/block2/conv3/bn/variance/EMA:0, group3/block2/conv2/bn/mean/EMA:0, group1/block1/conv2/bn/beta:0, group2/block4/conv1/bn/gamma:0, group3/block2/conv1/bn/variance/EMA:0, group2/block1/conv1/W:0, group1/block1/conv3/bn/beta:0, group0/block2/conv3/bn/gamma:0, group1/block3/conv2/bn/variance/EMA:0, group2/block0/conv3/bn/beta:0, group1/block2/conv2/bn/variance/EMA:0, group3/block0/conv3/bn/mean/EMA:0, group2/block1/conv2/bn/mean/EMA:0, group0/block2/conv3/W:0, group3/block2/conv3/bn/mean/EMA:0, group3/block0/conv3/W:0, group2/block0/conv3/bn/variance/EMA:0, group1/block3/conv1/bn/beta:0, group2/block4/conv2/bn/mean/EMA:0, group2/block0/conv1/bn/variance/EMA:0, group2/block5/conv2/bn/mean/EMA:0, group3/block2/conv2/bn/gamma:0, gro[1,0]<stdout>:up0/block2/conv2/bn/mean/EMA:0, group2/block2/conv2/bn/beta:0, group2/block3/conv1/bn/variance/EMA:0, group3/block1/conv3/bn/variance/EMA:0, group3/block1/conv2/bn/mean/EMA:0, group3/block0/conv2/bn/variance/EMA:0, group2/block3/conv2/W:0, group1/block1/conv3/W:0, group1/block3/conv1/bn/variance/EMA:0, group2/block0/conv2/bn/mean/EMA:0, group2/block1/conv2/W:0, group1/block3/conv3/bn/gamma:0, group2/block5/conv3/bn/beta:0, group3/block0/convshortcut/bn/variance/EMA:0, group1/block2/conv2/bn/gamma:0, group2/block1/conv1/bn/mean/EMA:0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:03 @sessinit.py:89]#033[0m #033[5m#033[31mWRN#033[0m The following variables are in the graph, but not found in the dict: fastrcnn/fc6/W, fastrcnn/fc6/b, fastrcnn/fc7/W, fastrcnn/fc7/b, fastrcnn/outputs/box/W, fastrcnn/outputs/box/b, fastrcnn/outputs/class/W, fastrcnn/outputs/class/b, fpn/lateral_1x1_c2/W, fpn/lateral_1x1_c2/b, fpn/lateral_1x1_c3/W, fpn/lateral_1x1_c3/b, fpn/lateral_1x1_c4/W, fpn/lateral_1x1_c4/b, fpn/lateral_1x1_c5/W, fpn/lateral_1x1_c5/b, fpn/posthoc_3x3_p2/W, fpn/posthoc_3x3_p2/b, fpn/posthoc_3x3_p3/W, fpn/posthoc_3x3_p3/b, fpn/posthoc_3x3_p4/W, fpn/posthoc_3x3_p4/b, fpn/posthoc_3x3_p5/W, fpn/posthoc_3x3_p5/b, global_step, learning_rate, maskrcnn/conv/W, maskrcnn/conv/b, maskrcnn/deconv/W, maskrcnn/deconv/b, maskrcnn/fcn0/W, maskrcnn/fcn0/b, maskrcnn/fcn1/W, maskrcnn/fcn1/b, maskrcnn/fcn2/W, maskrcnn/fcn2/b, maskrcnn/fcn3/W, maskrcnn/fcn3/b, rpn/box/W, rpn/box/b, rpn/class/W, rpn/class/b, rpn/conv0/W, rpn/conv0/b\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:03 @sessinit.py:89]#033[0m #033[5m#033[31mWRN#033[0m The following variables are in the dict, but not found in the graph: linear/W, linear/b\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:03 @sessinit.py:219]#033[0m Restoring 265 variables from dict ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:08 @varmanip.py:104]#033[0m #033[5m#033[31mWRN#033[0m Variable group0/block0/convshortcut/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:08 @varmanip.py:104]#033[0m #033[5m#033[31mWRN#033[0m Variable group0/block1/conv2/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:11 @varmanip.py:104]#033[0m #033[5m#033[31mWRN#033[0m Variable group0/block2/conv3/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:13 @varmanip.py:104]#033[0m #033[5m#033[31mWRN#033[0m Variable group0/block0/conv2/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:13 @varmanip.py:104]#033[0m #033[5m#033[31mWRN#033[0m Variable conv0/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:14 @varmanip.py:104]#033[0m #033[5m#033[31mWRN#033[0m Variable group0/block0/conv1/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:16 @varmanip.py:104]#033[0m #033[5m#033[31mWRN#033[0m Variable group0/block2/conv1/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:19 @varmanip.py:104]#033[0m #033[5m#033[31mWRN#033[0m Variable group0/block0/conv3/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:23 @varmanip.py:104]#033[0m #033[5m#033[31mWRN#033[0m Variable group0/block1/conv3/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:24 @varmanip.py:104]#033[0m #033[5m#033[31mWRN#033[0m Variable group0/block2/conv2/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:31 @varmanip.py:104]#033[0m #033[5m#033[31mWRN#033[0m Variable group0/block1/conv1/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:39 @base.py:244]#033[0m Graph Finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:39 @trainers.py:453]#033[0m Broadcasting initialized variables ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:40 @concurrency.py:40]#033[0m Starting EnqueueThread QueueInput/input_queue ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:42 @param.py:160]#033[0m [HyperParamSetter] At global_step=0, learning_rate is set to 0.003300\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:43 @eval.py:374]#033[0m [EvalCallback] Will evaluate every 1 epochs\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:43 @base.py:276]#033[0m Start Epoch 1 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:54 @param.py:163]#033[0m [HyperParamSetter] At global_step=1, learning_rate changes from 0.003300 to 0.003298\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:54 @base.py:286]#033[0m Epoch 1 (global_step 1) finished, time:11.6 seconds.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:54 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:54 @misc.py:111]#033[0m Estimated Time Left: 4 minutes 29 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:54 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:ip-10-0-98-32:39:60 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.98.32<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:ip-10-0-98-32:39:60 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:ip-10-0-98-32:39:60 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NCCL version 2.4.7+cuda10.0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:ip-10-0-98-32:39:60 [0] NCCL INFO Setting affinity for GPU 0 to ff\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:ip-10-0-98-32:39:60 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees enabled up to size -2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:ip-10-0-98-32:39:60 [0] NCCL INFO comm 0x7fd82c2fcd50 rank 0 nranks 1 cudaDev 0 nvmlDev 0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 0.09\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 11.64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 648.53\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 7.8917e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 11.64\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 0.085911\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m boxclass_losses/box_loss: 2.0181e-06\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m boxclass_losses/label_loss: 4.3214\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m learning_rate: 0.0033\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.64796\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.69226\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.64796\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 462\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 39\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.010468\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.67188\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 510\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.32557\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.5\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m total_cost: 6.3206\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m wd_cost: 0.62458\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @base.py:276]#033[0m Start Epoch 2 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @param.py:163]#033[0m [HyperParamSetter] At global_step=2, learning_rate changes from 0.003298 to 0.003296\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @base.py:286]#033[0m Epoch 2 (global_step 2) finished, time:0.122 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @misc.py:111]#033[0m Estimated Time Left: 2 minutes 37 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 8.18\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.12\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 6.6042e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.12221\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 8.1829\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.015191\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m boxclass_losses/label_loss: 2.2324\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.50681\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.51282\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 4.0513\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m learning_rate: 0.0032979\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.79655\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.98779\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.4704\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.79557\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 435.33\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 48.744\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 22.82\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 5.1026\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 3.0513\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.010391\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.6431\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 507.95\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 4.0513\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.35033\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.5\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.25641\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m total_cost: 3.9961\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @monitor.py:469]#033[0m wd_cost: 0.62459\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @base.py:276]#033[0m Start Epoch 3 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @param.py:163]#033[0m [HyperParamSetter] At global_step=3, learning_rate changes from 0.003296 to 0.003294\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @base.py:286]#033[0m Epoch 3 (global_step 3) finished, time:0.121 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @misc.py:111]#033[0m Estimated Time Left: 54.4 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:57 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 8.27\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.12\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 7.081e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.12088\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 8.2729\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.015678\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m boxclass_losses/label_loss: 1.4926\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.67697\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.68361\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 4.0333\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m learning_rate: 0.0032959\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.86117\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.98581\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.33991\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.86053\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 388.94\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 75.827\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 41.814\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 5.4172\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 3.0333\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.010581\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.59486\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 507.97\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 4.0333\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.3559\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.5\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.34181\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m total_cost: 3.0782\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m wd_cost: 0.62459\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @base.py:276]#033[0m Start Epoch 4 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @param.py:163]#033[0m [HyperParamSetter] At global_step=4, learning_rate changes from 0.003294 to 0.003292\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @base.py:286]#033[0m Epoch 4 (global_step 4) finished, time:0.103 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @misc.py:111]#033[0m Estimated Time Left: 30.1 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 9.75\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 5.0306e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.10255\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 9.7512\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.011454\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m boxclass_losses/label_loss: 1.1093\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.76299\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.76889\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 3.4852\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m learning_rate: 0.0032938\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.89842\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.98963\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.25343\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.89795\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 376.29\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 85.578\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 45.638\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 4.4961\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 2.4852\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.010782\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.52824\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 508.51\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 3.4852\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.33976\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.5\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.24967\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m total_cost: 2.5378\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @monitor.py:469]#033[0m wd_cost: 0.62459\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @base.py:276]#033[0m Start Epoch 5 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @param.py:163]#033[0m [HyperParamSetter] At global_step=5, learning_rate changes from 0.003292 to 0.003290\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @base.py:286]#033[0m Epoch 5 (global_step 5) finished, time:0.103 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @misc.py:111]#033[0m Estimated Time Left: 8.5 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:58 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 9.68\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 6.9857e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.10332\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 9.6784\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.0089291\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.89037\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.81451\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.81997\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 3.157\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m learning_rate: 0.0032918\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.92087\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.99193\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.20001\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.92051\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 365.84\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 97.164\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 45.055\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 3.9444\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 2.157\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.012046\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.45317\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 508.84\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 3.157\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.31613\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.38949\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.19449\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m total_cost: 2.1891\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m wd_cost: 0.62459\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @base.py:276]#033[0m Start Epoch 6 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @param.py:163]#033[0m [HyperParamSetter] At global_step=6, learning_rate changes from 0.003290 to 0.003288\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @base.py:286]#033[0m Epoch 6 (global_step 6) finished, time:0.103 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @misc.py:111]#033[0m Estimated Time Left: 7.76 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 9.70\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 5.4598e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.10312\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 9.6977\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.0072568\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.75771\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.84878\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.85395\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 2.9386\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m learning_rate: 0.0032898\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.93568\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.99345\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.16462\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.93539\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 361.9\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 101.66\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 45.045\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 3.3886\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 1.9386\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.012033\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.38569\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 509.06\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 2.9386\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.29929\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.31597\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.15778\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m total_cost: 1.9519\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m wd_cost: 0.6246\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @base.py:276]#033[0m Start Epoch 7 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @param.py:163]#033[0m [HyperParamSetter] At global_step=7, learning_rate changes from 0.003288 to 0.003286\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @base.py:286]#033[0m Epoch 7 (global_step 7) finished, time:0.112 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @misc.py:111]#033[0m Estimated Time Left: 7.17 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 8.96\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.11\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 4.9353e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.11162\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 8.9589\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.0060712\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.67225\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.8732\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.87816\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 2.783\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m learning_rate: 0.0032877\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.94634\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.99454\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.13978\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.9461\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 357.94\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 107.02\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 43.877\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 3.1585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 1.783\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.011563\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.33376\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 509.22\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 2.783\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.28649\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.2636\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.13163\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m total_cost: 1.788\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @monitor.py:469]#033[0m wd_cost: 0.6246\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @base.py:276]#033[0m Start Epoch 8 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @param.py:163]#033[0m [HyperParamSetter] At global_step=8, learning_rate changes from 0.003286 to 0.003284\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @base.py:286]#033[0m Epoch 8 (global_step 8) finished, time:0.101 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:55:59 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @misc.py:111]#033[0m Estimated Time Left: 6.75 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 9.87\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 4.22e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.10134\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 9.868\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.0051835\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.60901\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.89146\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.89626\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 2.6667\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m learning_rate: 0.0032856\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.95432\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.99535\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.12123\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.95411\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 357.95\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 107.91\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 43.301\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 2.8378\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 1.6667\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.012371\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.29344\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 509.33\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 2.6667\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.27899\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.22444\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.11207\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m total_cost: 1.6658\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m wd_cost: 0.62461\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @base.py:276]#033[0m Start Epoch 9 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @param.py:163]#033[0m [HyperParamSetter] At global_step=9, learning_rate changes from 0.003284 to 0.003282\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @base.py:286]#033[0m Epoch 9 (global_step 9) finished, time:0.126 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @misc.py:111]#033[0m Estimated Time Left: 6.36 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 7.90\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.13\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 6.2943e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.12651\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 7.9044\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.0054822\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.56928\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.90534\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.91029\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 2.7118\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m learning_rate: 0.0032836\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.95888\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.99437\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.13371\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.9587\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 351.87\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 109.41\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 47.588\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 3.1302\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 1.7118\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.011184\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.26097\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 509.29\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 2.7118\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.29053\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.26171\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.16453\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m total_cost: 1.6052\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @monitor.py:469]#033[0m wd_cost: 0.62461\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @base.py:276]#033[0m Start Epoch 10 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @param.py:163]#033[0m [HyperParamSetter] At global_step=10, learning_rate changes from 0.003282 to 0.003280\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @base.py:286]#033[0m Epoch 10 (global_step 10) finished, time:0.125 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @misc.py:111]#033[0m Estimated Time Left: 5.94 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:00 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 7.97\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.13\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 7.1526e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.12553\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 7.9663\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.0083001\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.56667\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.91495\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.92147\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 3.4953\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m learning_rate: 0.0032816\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.95864\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.9897\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.1679\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.95848\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 347.03\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 109.61\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 51.003\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 4.3601\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 2.4953\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.010674\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.23355\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 508.5\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 3.4953\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.31428\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.2914\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.20633\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m total_cost: 1.6117\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m wd_cost: 0.62462\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @base.py:276]#033[0m Start Epoch 11 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @param.py:163]#033[0m [HyperParamSetter] At global_step=11, learning_rate changes from 0.003280 to 0.003277\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @base.py:286]#033[0m Epoch 11 (global_step 11) finished, time:0.128 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @misc.py:111]#033[0m Estimated Time Left: 5.51 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 7.81\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.13\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 9.0599e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.1281\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 7.8061\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.013228\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.53816\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.92209\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.93057\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 4.4815\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m learning_rate: 0.0032795\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.95764\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.9851\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.17792\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.9575\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 340.76\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 107.8\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 56.337\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 7.1012\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 3.4815\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.010076\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.20971\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 507.52\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 4.4815\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.32942\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.31559\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.24039\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m total_cost: 1.5737\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m wd_cost: 0.62462\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @base.py:276]#033[0m Start Epoch 12 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @param.py:163]#033[0m [HyperParamSetter] At global_step=12, learning_rate changes from 0.003277 to 0.003275\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @base.py:286]#033[0m Epoch 12 (global_step 12) finished, time:0.13 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @misc.py:111]#033[0m Estimated Time Left: 5.13 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 7.72\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.13\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 6.3419e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.12955\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 7.7189\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.020213\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.50268\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.92759\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.93813\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 5.5169\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m learning_rate: 0.0032775\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.95866\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.98313\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.17143\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.95854\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 327.74\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 110\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 64.894\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 9.3746\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 4.5169\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.0098352\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.18985\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 506.48\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 5.5169\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.33794\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.33565\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.26863\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m total_cost: 1.5186\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @monitor.py:469]#033[0m wd_cost: 0.62463\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:01 @base.py:276]#033[0m Start Epoch 13 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @param.py:163]#033[0m [HyperParamSetter] At global_step=13, learning_rate changes from 0.003275 to 0.003273\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @base.py:286]#033[0m Epoch 13 (global_step 13) finished, time:0.0943 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @misc.py:111]#033[0m Estimated Time Left: 4.7 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 10.60\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.09\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 4.9591e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.094351\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 10.599\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.026855\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.47327\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.93222\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.94448\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 6.3885\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m learning_rate: 0.0032754\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.96053\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.98251\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.17145\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.96042\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 315.02\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 112.36\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 72.919\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 11.699\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 5.3885\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.0097345\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.17318\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 505.61\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 6.3885\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.34334\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.35253\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.2924\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m total_cost: 1.4791\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m wd_cost: 0.62463\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @base.py:276]#033[0m Start Epoch 14 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @param.py:163]#033[0m [HyperParamSetter] At global_step=14, learning_rate changes from 0.003273 to 0.003271\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @base.py:286]#033[0m Epoch 14 (global_step 14) finished, time:0.132 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @misc.py:111]#033[0m Estimated Time Left: 4.27 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 7.60\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.13\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 5.9128e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.13151\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 7.6038\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.031452\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.44655\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.93636\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.9499\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 7.0337\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m learning_rate: 0.0032733\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.96304\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.98287\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.17009\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.96294\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 301.94\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 117.89\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 78.587\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 13.583\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 6.0337\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.0096648\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.15895\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 504.97\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 7.0337\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.34795\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.36693\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.31266\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m total_cost: 1.4413\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @monitor.py:469]#033[0m wd_cost: 0.62463\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @base.py:276]#033[0m Start Epoch 15 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @param.py:163]#033[0m [HyperParamSetter] At global_step=15, learning_rate changes from 0.003271 to 0.003269\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @base.py:286]#033[0m Epoch 15 (global_step 15) finished, time:0.0963 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @misc.py:111]#033[0m Estimated Time Left: 3.82 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:02 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 10.38\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 5.8174e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.096371\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 10.377\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.034311\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.42133\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.9401\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.95457\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 7.4964\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m learning_rate: 0.0032713\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.96454\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.98253\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.16347\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.96445\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 288.91\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 123.11\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 85.147\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 14.833\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 6.4964\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.009528\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.14689\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 504.5\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 7.4964\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.35239\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.37932\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.33011\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m total_cost: 1.4002\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m wd_cost: 0.62463\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @base.py:276]#033[0m Start Epoch 16 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @param.py:163]#033[0m [HyperParamSetter] At global_step=16, learning_rate changes from 0.003269 to 0.003267\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @base.py:286]#033[0m Epoch 16 (global_step 16) finished, time:0.101 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @param.py:160]#033[0m [HyperParamSetter] At global_step=16, learning_rate is set to 0.000125\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @misc.py:111]#033[0m Estimated Time Left: 3.26 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 9.89\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 6.0558e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.10106\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 9.8949\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.034898\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.39805\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.94388\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.95863\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 7.6307\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m learning_rate: 0.0032693\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.96524\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.98162\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.15603\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.96516\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 279.89\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 128.19\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 88.349\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 15.562\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 6.6307\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.0093708\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.1364\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 504.37\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 7.6307\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.35665\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.3901\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.34528\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m total_cost: 1.3594\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @monitor.py:469]#033[0m wd_cost: 0.62464\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @base.py:276]#033[0m Start Epoch 17 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @param.py:163]#033[0m [HyperParamSetter] At global_step=17, learning_rate changes from 0.003267 to 0.003265\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @base.py:286]#033[0m Epoch 17 (global_step 17) finished, time:0.125 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @misc.py:111]#033[0m Estimated Time Left: 2.85 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:03 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 7.98\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.13\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 5.4598e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.12535\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 7.9774\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.035485\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.3804\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.94703\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.96218\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 7.8343\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m learning_rate: 0.000125\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.96609\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.98106\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.14912\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.96602\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 270.62\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 132.13\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 93.131\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 16.115\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 6.8343\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.0091871\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.12714\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 504.17\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 7.8343\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.36083\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.39954\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.35858\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m total_cost: 1.326\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m wd_cost: 0.62464\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @base.py:276]#033[0m Start Epoch 18 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @param.py:163]#033[0m [HyperParamSetter] At global_step=18, learning_rate changes from 0.003265 to 0.003263\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @base.py:286]#033[0m Epoch 18 (global_step 18) finished, time:0.0933 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @misc.py:111]#033[0m Estimated Time Left: 2.44 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 10.71\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.09\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 4.2439e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.093354\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 10.712\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.037681\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.36828\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.94948\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.96532\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 8.1798\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m learning_rate: 0.0032651\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.96645\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.98018\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.14389\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.96638\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 262.28\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 136.77\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 96.272\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 16.686\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 7.1798\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.0091095\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.11872\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 503.82\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 8.1798\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.36489\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.40788\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.37031\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m total_cost: 1.3023\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m wd_cost: 0.62464\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @base.py:276]#033[0m Start Epoch 19 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @param.py:163]#033[0m [HyperParamSetter] At global_step=19, learning_rate changes from 0.003263 to 0.003261\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @base.py:286]#033[0m Epoch 19 (global_step 19) finished, time:0.0964 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @misc.py:111]#033[0m Estimated Time Left: 2.02 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 10.36\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 4.8637e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.096492\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 10.364\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.03936\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.35372\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.9515\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.9681\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 8.5669\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m learning_rate: 0.0032631\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.96718\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.9798\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.13819\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.96711\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 258.4\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 136.54\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 99.382\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 17.675\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 7.5669\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.0090331\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.11108\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 503.43\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 8.5669\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.3684\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.41527\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.38072\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m total_cost: 1.276\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @monitor.py:469]#033[0m wd_cost: 0.62464\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @base.py:276]#033[0m Start Epoch 20 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @param.py:163]#033[0m [HyperParamSetter] At global_step=20, learning_rate changes from 0.003261 to 0.003259\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @base.py:286]#033[0m Epoch 20 (global_step 20) finished, time:0.0986 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:04 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:05 @saver.py:81]#033[0m Model saved to /opt/ml/model/model-20.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:05 @param.py:163]#033[0m [HyperParamSetter] At global_step=20, learning_rate changes from 0.000125 to 0.000013\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:05 @misc.py:111]#033[0m Estimated Time Left: 1.63 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:05 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 10.14\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 5.2214e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.098628\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 10.139\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.040734\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.33736\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.95345\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.97059\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 8.8345\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m learning_rate: 0.003261\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.96697\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.97861\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.13503\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.96691\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 255.1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 136.81\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 101.77\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 18.324\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 7.8345\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.0089663\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.10417\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 503.17\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 8.8345\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.37123\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.42188\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.39002\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m total_cost: 1.2509\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m wd_cost: 0.62465\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @base.py:276]#033[0m Start Epoch 21 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @param.py:163]#033[0m [HyperParamSetter] At global_step=21, learning_rate changes from 0.003259 to 0.003257\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @base.py:286]#033[0m Epoch 21 (global_step 21) finished, time:0.129 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @misc.py:111]#033[0m Estimated Time Left: 1.27 seconds\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 7.73\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.13\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 8.4639e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.12936\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 7.7303\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.042716\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.32469\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.95476\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.97282\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 9.3019\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m learning_rate: 1.25e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.96642\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.97718\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.13392\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.96637\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 252.51\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 136.83\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 103.61\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 19.058\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 8.3019\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.0089126\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.097944\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 502.7\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 9.3019\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.37507\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.4278\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.39836\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m total_cost: 1.2328\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m wd_cost: 0.62465\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @base.py:276]#033[0m Start Epoch 22 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @param.py:163]#033[0m [HyperParamSetter] At global_step=22, learning_rate changes from 0.003257 to 0.003255\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @base.py:286]#033[0m Epoch 22 (global_step 22) finished, time:0.0953 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @misc.py:111]#033[0m Estimated Time Left: 0.809 second\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 10.50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 6.485e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.095235\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 10.5\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.044442\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.31256\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.95608\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.97483\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 9.6492\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m learning_rate: 0.003257\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.96684\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.97681\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.12986\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.96679\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 250.03\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 136.77\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 105.48\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 19.719\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 8.6492\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.0088641\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.092333\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 502.35\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 9.6492\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.37852\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.43314\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.40587\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m total_cost: 1.2127\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @monitor.py:469]#033[0m wd_cost: 0.62465\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:06 @base.py:276]#033[0m Start Epoch 23 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @param.py:163]#033[0m [HyperParamSetter] At global_step=23, learning_rate changes from 0.003255 to 0.003253\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @base.py:286]#033[0m Epoch 23 (global_step 23) finished, time:0.14 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @misc.py:111]#033[0m Estimated Time Left: 0.425 second\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 7.17\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.14\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 0.00010705\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.13941\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 7.1733\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.047271\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.30265\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.95671\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.97664\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 10.252\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m learning_rate: 0.0032549\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.96582\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.97506\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.13022\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.96577\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 249.02\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 135.48\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 107.32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 20.172\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 9.252\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.008634\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.087315\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 501.75\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 10.252\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.38278\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.43796\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.41267\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m total_cost: 1.2007\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @monitor.py:469]#033[0m wd_cost: 0.62465\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @base.py:276]#033[0m Start Epoch 24 ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @param.py:163]#033[0m [HyperParamSetter] At global_step=24, learning_rate changes from 0.003253 to 0.003251\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @base.py:286]#033[0m Epoch 24 (global_step 24) finished, time:0.141 second.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @trainers.py:419]#033[0m Running horovod broadcast ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @saver.py:81]#033[0m Model saved to /opt/ml/model/model-24.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:07 @eval.py:414]#033[0m Running evaluation ...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loading annotations into memory...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Done (t=0.00s)\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:creating index...\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:index created!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @dataset.py:50]#033[0m Instances loaded from /opt/ml/input/data/train/annotations/instances_val2017.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @performance.py:179]#033[0m [ThroughputTracker] Over last epoch, MeanEpochThroughput: 7.11\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @performance.py:180]#033[0m [ThroughputTracker] Over last epoch, EpochWallClockDuration: 0.14\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @performance.py:181]#033[0m [ThroughputTracker] Over last epoch, CallbackOverheadDuration: 0.00\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m PeakMemory(MB)/gpu:0: 4585\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m QueueInput/queue_size: 50\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m Throughput/CallbackOverheadDuration: 7.4625e-05\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m Throughput/EpochWallClockDuration: 0.14062\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m Throughput/MeanEpochThroughput: 7.1113\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m boxclass_losses/box_loss: 0.048764\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m boxclass_losses/label_loss: 0.29198\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m boxclass_losses/label_metrics/accuracy: 0.95756\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m boxclass_losses/label_metrics/false_negative: 0.97829\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m boxclass_losses/label_metrics/fg_accuracy: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m boxclass_losses/num_fg_label: 10.658\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m learning_rate: 0.0032528\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m mAP(bbox)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m mAP(bbox)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m mAP(bbox)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m mAP(bbox)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m mAP(segm)/IoU=0.5:0.95: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m mAP(segm)/IoU=0.75: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m mAP(segm)/large: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m mAP(segm)/medium: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m mAP(segm)/small: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m maskrcnn_loss/accuracy: 0.96446\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m maskrcnn_loss/fg_pixel_ratio: 0.97306\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m maskrcnn_loss/maskrcnn_loss: 0.13136\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m maskrcnn_loss/pos_accuracy: 0.96442\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 247.32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 134.53\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 109.56\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 20.584\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level2: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level3: 1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level4: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m multilevel_roi_align_mask/fpn_map_rois_to_levels/num_roi_level5: 9.6579\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m rpn_losses/box_loss: 0.0085569\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m rpn_losses/label_loss: 0.082687\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_bg: 501.34\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m sample_fast_rcnn_targets/num_fg: 10.658\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.38657\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.44234\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.41883\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m total_cost: 1.188\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @monitor.py:469]#033[0m wd_cost: 0.62465\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @base.py:290]#033[0m Training has finished!\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:#033[32m[0402 10:56:08 @train.py:321]#033[0m Total duration: 94.25\u001b[0m\n",
      "\u001b[34mmpirun exit code:0\u001b[0m\n",
      "\u001b[34m2020-04-02 10:56:09,405 sagemaker_tensorflow_container.training WARNING  Your model will NOT be servable with SageMaker TensorFlow Serving container. The model artifact was not saved in the TensorFlow SavedModel directory structure:\u001b[0m\n",
      "\u001b[34mhttps://www.tensorflow.org/guide/saved_model#structure_of_a_savedmodel_directory\u001b[0m\n",
      "\u001b[34m2020-04-02 10:56:09,405 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-04-02 10:56:09 Uploading - Uploading generated training model\n",
      "2020-04-02 10:57:57 Completed - Training job completed\n",
      "Training seconds: 358\n",
      "Billable seconds: 358\n"
     ]
    }
   ],
   "source": [
    "mask_rcnn_estimator.fit(inputs=data_channels, logs=\"All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
